# pipeline/modules/change_detector.py
from enum import Enum
from enum import auto
from typing import List
from typing import Tuple

import cv2
import numpy as np
import torch

from ..utils.progress_logger import create_stage_progress
from .decoder import GPUDecoder
from .base_detector import BaseDetector, ConfigManager
from services.common.logger import get_logger

logger = get_logger('change_detector')


class ChangeType(Enum):
    """
    å®šä¹‰å…³é”®å¸§çš„å˜åŒ–æ€§è´¨
    """
    TEXT_APPEARED = auto()      # æ–‡æœ¬å‡ºç° (ä»æ— åˆ°æœ‰)
    TEXT_DISAPPEARED = auto()   # æ–‡æœ¬æ¶ˆå¤± (ä»æœ‰åˆ°æ— )
    CONTENT_CHANGED = auto()    # æ–‡æœ¬å†…å®¹å˜åŒ– (ä»æœ‰åˆ°æœ‰ï¼Œä½†å†…å®¹ä¸åŒ)

class ChangeDetector(BaseDetector):
    """
    é€šè¿‡dHashå’Œåƒç´ æ ‡å‡†å·®çš„æ··åˆæ–¹æ³•ï¼Œé«˜æ•ˆæ£€æµ‹å­—å¹•å˜åŒ–çš„å…³é”®å¸§åŠå…¶å˜åŒ–ç±»å‹ã€‚
    """
    def __init__(self, config):
        """
        åˆå§‹åŒ–å˜åŒ–æ£€æµ‹å™¨

        Args:
            config: æ£€æµ‹å™¨é…ç½®
        """
        # ä½¿ç”¨ConfigManageréªŒè¯å’Œè§„èŒƒåŒ–é…ç½®
        required_keys = []
        optional_keys = {
            'dhash_size': 8,
            'hamming_threshold': 3,
            'frame_memory_estimate_mb': 0.307,
            'progress_interval_frames': 1000,
            'progress_interval_batches': 50
        }

        validated_config = ConfigManager.validate_config(config, required_keys, optional_keys)

        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(validated_config)

        # è®¾ç½®å˜åŒ–æ£€æµ‹å™¨ç‰¹æœ‰çš„é…ç½®
        self.hash_size = ConfigManager.validate_range(
            validated_config['dhash_size'], 1, 32, 'dhash_size'
        )

        self.hamming_threshold = ConfigManager.validate_range(
            validated_config['hamming_threshold'], 0, 64, 'hamming_threshold'
        )

        logger.info("å˜åŒ–æ£€æµ‹å™¨å·²åŠ è½½ (V2 - äº‹ä»¶é©±åŠ¨)")

    def find_key_frames(self, video_path: str, decoder: GPUDecoder, subtitle_area: Tuple[int, int, int, int]) -> List[Tuple[int, ChangeType]]:
        """
        æ‰§è¡Œå˜åŒ–æ£€æµ‹ï¼Œæ‰¾å‡ºæ‰€æœ‰å…³é”®å¸§çš„ç´¢å¼•åŠå…¶å˜åŒ–ç±»å‹ã€‚

        Args:
            video_path (str): è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
            decoder (GPUDecoder): è§£ç å™¨å®ä¾‹ã€‚
            subtitle_area (Tuple[int, int, int, int]): å­—å¹•åŒºåŸŸ (x1, y1, x2, y2)ã€‚

        Returns:
            List[Tuple[int, ChangeType]]: åŒ…å«æ‰€æœ‰å…³é”®äº‹ä»¶çš„åˆ—è¡¨ (å¸§å·, å˜åŒ–ç±»å‹)ã€‚
        """
        print("ğŸ” å¼€å§‹åˆ†æå­—å¹•å˜åŒ–...")
        x1, y1, x2, y2 = subtitle_area

        # 1. æ‰¹é‡è®¡ç®—æ‰€æœ‰å¸§çš„dHashå’Œæ ‡å‡†å·®
        all_hashes, all_stds = self._compute_metrics_for_all_frames(video_path, decoder, (x1, y1, x2, y2))
        print(f"ğŸ“Š å®Œæˆç‰¹å¾è®¡ç®—: {len(all_hashes)} å¸§")

        # 2. ä½¿ç”¨å¤§æ´¥æ³•è‡ªåŠ¨ç¡®å®šç©ºç™½å¸§é˜ˆå€¼
        blank_threshold = self._get_otsu_threshold(all_stds)
        print(f"ğŸ¯ ç©ºç™½å¸§é˜ˆå€¼: {blank_threshold:.4f}")

        # 3. æ‰¾å‡ºæ‰€æœ‰å˜åŒ–ç‚¹
        key_events = self._detect_change_points(all_hashes, all_stds, blank_threshold)
        
        print(f"âœ… æ£€æµ‹åˆ° {len(key_events)} ä¸ªå…³é”®å˜åŒ–äº‹ä»¶")

        return key_events

    def _compute_metrics_for_all_frames(self, video_path: str, decoder: GPUDecoder, crop_rect: Tuple[int, int, int, int]) -> Tuple[List[np.ndarray], np.ndarray]:
        """åœ¨GPUä¸Šæ‰¹é‡è®¡ç®—æ‰€æœ‰å¸§çš„æŒ‡æ ‡"""
        all_hashes = []
        all_stds = []
        x1, y1, x2, y2 = crop_rect

        # ç®€å•çš„è®¡æ•°å™¨ï¼Œä¸ä½¿ç”¨è¿›åº¦æ¡ï¼ˆå› ä¸ºæ€»å¸§æ•°æœªçŸ¥ï¼‰
        frame_count = 0
        batch_count = 0
        
        print("ğŸ”„ æ­£åœ¨è®¡ç®—è§†é¢‘ç‰¹å¾...")
        
        for batch_tensor, _ in decoder.decode(video_path):
            # è£å‰ªå­—å¹•åŒºåŸŸ
            cropped_batch = batch_tensor[:, :, y1:y2, x1:x2]

            # --- åœ¨GPUä¸Šæ‰¹é‡è®¡ç®— --- #
            # 1. è®¡ç®—æ ‡å‡†å·®
            stds = torch.std(cropped_batch.float().view(cropped_batch.size(0), -1), dim=1)
            all_stds.extend(stds.cpu().numpy())

            # 2. è®¡ç®—dHash
            grayscale_batch = cropped_batch.float().mean(dim=1, keepdim=True)
            resized_batch = torch.nn.functional.interpolate(grayscale_batch, size=(self.hash_size, self.hash_size + 1), mode='bilinear', align_corners=False)
            diff = resized_batch[:, :, :, 1:] > resized_batch[:, :, :, :-1]
            hashes_np = diff.cpu().numpy().astype(np.uint8).reshape(diff.shape[0], -1)
            all_hashes.extend(hashes_np)
            
            # è®°å½•batchå¤§å°ä»¥ä¾¿åç»­æ¸…ç†
            batch_size = batch_tensor.size(0)
            
            # æ˜¾å¼æ¸…ç†GPUä¸­é—´å˜é‡ï¼Œé‡Šæ”¾æ˜¾å­˜
            del grayscale_batch, resized_batch, diff, hashes_np, stds
            del cropped_batch, batch_tensor
            
            frame_count += batch_size
            batch_count += 1
            
            # æ¯50ä¸ªbatchæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if batch_count % 50 == 0:
                print(f"  ğŸ“Š å·²å¤„ç† {frame_count} å¸§...")
                # é—´éš”æ€§å¼ºåˆ¶åƒåœ¾å›æ”¶
                import gc
                gc.collect()
            
        print(f"âœ… ç‰¹å¾è®¡ç®—å®Œæˆ: å…±å¤„ç† {frame_count} å¸§")
        
        # GPU èµ„æºé‡Šæ”¾
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
            
        return all_hashes, np.array(all_stds)

    def _get_otsu_threshold(self, stds: np.ndarray) -> float:
        """å¯¹æ ‡å‡†å·®åˆ—è¡¨ä½¿ç”¨å¤§æ´¥æ³•ï¼ˆOtsu's methodï¼‰æ‰¾åˆ°æœ€ä½³é˜ˆå€¼"""
        if stds.max() == stds.min(): return 0.0
        stds_normalized = (255 * (stds - stds.min()) / (stds.max() - stds.min())).astype(np.uint8)
        threshold_otsu, _ = cv2.threshold(stds_normalized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        original_threshold = threshold_otsu / 255 * (stds.max() - stds.min()) + stds.min()
        return float(original_threshold)

    def _detect_change_points(self, hashes: List[np.ndarray], stds: np.ndarray, blank_threshold: float) -> List[Tuple[int, ChangeType]]:
        """æ ¹æ®å“ˆå¸Œå’Œæ ‡å‡†å·®æ‰¾å‡ºæ‰€æœ‰å˜åŒ–ç‚¹äº‹ä»¶"""
        key_events = []
        is_blank_list = (stds < blank_threshold)

        # ç¬¬0å¸§ç‰¹æ®Šå¤„ç†
        if not is_blank_list[0]:
            key_events.append((0, ChangeType.TEXT_APPEARED))

        print(f"ğŸ”„ æ­£åœ¨åˆ†æ {len(hashes)} å¸§çš„å˜åŒ–ç‚¹...")
        
        for i in range(1, len(hashes)):
            prev_is_blank = is_blank_list[i-1]
            curr_is_blank = is_blank_list[i]

            if prev_is_blank and not curr_is_blank:
                # ä»æ— åˆ°æœ‰
                key_events.append((i, ChangeType.TEXT_APPEARED))
            elif not prev_is_blank and curr_is_blank:
                # ä»æœ‰åˆ°æ— 
                key_events.append((i, ChangeType.TEXT_DISAPPEARED))
            elif not prev_is_blank and not curr_is_blank:
                # éƒ½æ˜¯æœ‰ï¼Œåˆ¤æ–­å†…å®¹æ˜¯å¦å˜åŒ–
                hamming_distance = np.count_nonzero(hashes[i-1] != hashes[i])
                if hamming_distance > self.hamming_threshold:
                    key_events.append((i, ChangeType.CONTENT_CHANGED))
            
            # æ¯1000å¸§æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if i % 1000 == 0:
                progress_percent = (i / len(hashes)) * 100
                print(f"  ğŸ” å˜åŒ–æ£€æµ‹è¿›åº¦: {i}/{len(hashes)} ({progress_percent:.1f}%), å·²æ‰¾åˆ° {len(key_events)} ä¸ªäº‹ä»¶")
        
        print(f"âœ… å˜åŒ–æ£€æµ‹å®Œæˆï¼Œå…±æ‰¾åˆ° {len(key_events)} ä¸ªå…³é”®äº‹ä»¶")

        return key_events

    def detect(self, video_path: str, decoder, subtitle_area: Tuple[int, int, int], **kwargs) -> List[Tuple[int, ChangeType]]:
        """
        å®ç°åŸºç±»çš„æŠ½è±¡æ£€æµ‹æ–¹æ³•

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            decoder: GPUè§£ç å™¨å®ä¾‹
            subtitle_area: å­—å¹•åŒºåŸŸåæ ‡
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            å…³é”®äº‹ä»¶åˆ—è¡¨ (å¸§ç´¢å¼•, å˜åŒ–ç±»å‹)
        """
        self._start_processing()
        try:
            key_events = self.find_key_frames(video_path, decoder, subtitle_area)
            return key_events
        finally:
            self._finish_processing()

    def get_detector_name(self) -> str:
        """
        è·å–æ£€æµ‹å™¨åç§°

        Returns:
            æ£€æµ‹å™¨åç§°
        """
        return "ChangeDetector"
