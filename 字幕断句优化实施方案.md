# å­—å¹•æ–­å¥ä¼˜åŒ–è®¾è®¡ä¸å®æ–½æ–¹æ¡ˆ

## ğŸ“‹ è®¾è®¡ç›®æ ‡

### æ ¸å¿ƒç›®æ ‡
1. **æå‡å¤šè¯­è¨€å­—å¹•æ–­å¥è´¨é‡**ï¼šä½¿å­—å¹•æ–­å¥æ›´ç¬¦åˆè‡ªç„¶è¯­è¨€ä¹ æƒ¯
2. **ä¿æŒå‘åå…¼å®¹**ï¼šä¸ç ´åç°æœ‰å·¥ä½œæµç¨‹å’ŒåŠŸèƒ½
3. **æ¸è¿›å¼æ”¹è¿›**ï¼šå…è®¸é€æ­¥å¯ç”¨æ–°åŠŸèƒ½ï¼Œé™ä½é£é™©
4. **å¯é…ç½®æ€§**ï¼šæä¾›çµæ´»çš„é…ç½®é€‰é¡¹ï¼Œé€‚åº”ä¸åŒåœºæ™¯éœ€æ±‚

### è´¨é‡æŒ‡æ ‡
- è¯­ä¹‰è¿è´¯æ€§æå‡ï¼šå‡å°‘ä¸åˆç†æ–­å¥æ¯”ä¾‹ â‰¥ 30%
- å¤šè¯­è¨€æ”¯æŒï¼šè‡³å°‘æ”¯æŒä¸­è‹±æ–‡ï¼Œå¯æ‰©å±•å…¶ä»–è¯­è¨€
- æ€§èƒ½å½±å“ï¼šæ–°å¢åŠŸèƒ½å¯¹å¤„ç†æ—¶é—´å½±å“ â‰¤ 20%

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ
```
ç°æœ‰ç³»ç»Ÿï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å­—å¹•é‡æ„æ‰§è¡Œå™¨  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¯çº§å¯¹é½æ¨¡å—    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ–­å¥é€»è¾‘        â”‚ â† æœ¬æ¬¡æ”¹é€ ç‚¹
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ”¹é€ åç³»ç»Ÿï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å­—å¹•é‡æ„æ‰§è¡Œå™¨  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¯çº§å¯¹é½æ¨¡å—    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ–­å¥ç­–ç•¥ç®¡ç†å™¨  â”‚ â† æ–°å¢ï¼šç­–ç•¥é€‰æ‹©ä¸åè°ƒ
â”‚ â”œâ”€å¼ºæ ‡ç‚¹ç­–ç•¥    â”‚
â”‚ â”œâ”€è¯­ä¹‰æ–­å¥ç­–ç•¥  â”‚ â† æ–°å¢ï¼šå¯é€‰spacyé›†æˆ
â”‚ â”œâ”€å¼±æ ‡ç‚¹ç­–ç•¥    â”‚
â”‚ â””â”€å¹³è¡¡å…œåº•ç­–ç•¥  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### 1. æ–­å¥ç­–ç•¥ç®¡ç†å™¨ (BreakStrategyManager)
- **èŒè´£**ï¼šåè°ƒä¸åŒæ–­å¥ç­–ç•¥çš„æ‰§è¡Œé¡ºåº
- **è¾“å…¥**ï¼šè¯åˆ—è¡¨ã€é…ç½®å‚æ•°
- **è¾“å‡º**ï¼šåˆ†å‰²åçš„ç‰‡æ®µåˆ—è¡¨
- **ç‰¹æ€§**ï¼šç­–ç•¥é“¾å¼æ‰§è¡Œï¼Œå‰ä¸€ä¸ªç­–ç•¥å¤±è´¥æ—¶è‡ªåŠ¨å°è¯•ä¸‹ä¸€ä¸ª

#### 2. è¯­ä¹‰æ–­å¥ç­–ç•¥ (SemanticBreakStrategy)
- **å¯é€‰ä¾èµ–**ï¼šspacyï¼ˆé€šè¿‡é…ç½®å¼€å…³æ§åˆ¶ï¼‰
- **æ”¯æŒè¯­è¨€**ï¼šä¸­æ–‡(zh)ã€è‹±æ–‡(en)ï¼Œå¯æ‰©å±•
- **å›é€€æœºåˆ¶**ï¼šspacyä¸å¯ç”¨æ—¶è‡ªåŠ¨ä½¿ç”¨å¢å¼ºè§„åˆ™

#### 3. é…ç½®ç®¡ç†ç³»ç»Ÿ
```python
# config/subtitle_breaking.yml
subtitle_breaking:
  enabled: true
  strategies:
    strong_punctuation:
      enabled: true
      punctuation: ["ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"]
      min_duration: 1.0
      
    semantic:
      enabled: false  # é»˜è®¤å…³é—­
      use_spacy: false
      spacy_models:
        en: "en_core_web_sm"
        zh: "zh_core_web_sm"
      fallback_to_rules: true
      
    weak_punctuation:
      enabled: true
      punctuation: ["ï¼Œ", "ã€", "ï¼›", ",", ";", ":"]
      require_balance: true
      
    balanced_fallback:
      enabled: true
      min_balance_ratio: 0.5
      prefer_natural_breaks: true
  
  limits:
    max_cpl: 42
    max_cps: 18.0
    min_duration: 1.0
    max_duration: 7.0
```

## ğŸ› ï¸ å®æ–½æ­¥éª¤

### é˜¶æ®µä¸€ï¼šåŸºç¡€æ¶æ„æ”¹é€  (é¢„è®¡2-3å¤©)

#### 1.1 åˆ›å»ºç­–ç•¥æ¥å£å’ŒåŸºç±»
```python
# services/common/subtitle/break_strategy.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional

class BreakStrategy(ABC):
    """æ–­å¥ç­–ç•¥åŸºç±»"""
    
    @abstractmethod
    def can_handle(self, words: List[Dict[str, Any]], config: Dict) -> bool:
        """æ£€æŸ¥ç­–ç•¥æ˜¯å¦é€‚ç”¨"""
        pass
    
    @abstractmethod
    def break_segments(self, words: List[Dict[str, Any]], config: Dict) -> List[List[Dict[str, Any]]]:
        """æ‰§è¡Œæ–­å¥ï¼Œè¿”å›ç‰‡æ®µåˆ—è¡¨"""
        pass
    
    @abstractmethod
    def get_strategy_name(self) -> str:
        """è·å–ç­–ç•¥åç§°"""
        pass
```

#### 1.2 å®ç°ç°æœ‰é€»è¾‘çš„ç­–ç•¥å°è£…
```python
class StrongPunctuationStrategy(BreakStrategy):
    """å¼ºæ ‡ç‚¹æ–­å¥ç­–ç•¥"""
    
    def can_handle(self, words, config):
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼ºæ ‡ç‚¹
        return has_strong_punctuation(words)
    
    def break_segments(self, words, config):
        # å°è£…ç°æœ‰å¼ºæ ‡ç‚¹æ–­å¥é€»è¾‘
        return break_at_strong_punctuation(words, config)
```

#### 1.3 åˆ›å»ºç­–ç•¥ç®¡ç†å™¨
```python
class BreakStrategyManager:
    """æ–­å¥ç­–ç•¥ç®¡ç†å™¨"""
    
    def __init__(self, config: Dict):
        self.strategies = []
        self.config = config
        self._init_strategies()
    
    def _init_strategies(self):
        # æŒ‰ä¼˜å…ˆçº§æ³¨å†Œç­–ç•¥
        self.strategies.append(StrongPunctuationStrategy())
        if self.config.get('semantic', {}).get('enabled', False):
            self.strategies.append(SemanticBreakStrategy())
        self.strategies.append(WeakPunctuationStrategy())
        self.strategies.append(BalancedFallbackStrategy())
    
    def execute(self, words: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰§è¡Œæ–­å¥ç­–ç•¥é“¾"""
        for strategy in self.strategies:
            if strategy.can_handle(words, self.config):
                segments = strategy.break_segments(words, self.config)
                if self._validate_segments(segments):
                    return segments
        # å…œåº•ï¼šä½¿ç”¨åŸå§‹é€»è¾‘
        return self._fallback_break(words)
```

### é˜¶æ®µäºŒï¼šå¢å¼ºè§„åˆ™å®ç° (é¢„è®¡3-4å¤©)

#### 2.1 å®ç°å¢å¼ºçš„å¼±æ ‡ç‚¹ç­–ç•¥
```python
class WeakPunctuationStrategy(BreakStrategy):
    """å¢å¼ºå¼±æ ‡ç‚¹ç­–ç•¥"""
    
    def break_segments(self, words, config):
        # 1. æ”¶é›†æ‰€æœ‰å¼±æ ‡ç‚¹ä½ç½®
        weak_break_indices = self._find_weak_punctuation_breaks(words)
        
        # 2. è¯„ä¼°æ¯ä¸ªæ–­ç‚¹çš„è´¨é‡
        scored_breaks = []
        for idx in weak_break_indices:
            score = self._evaluate_break_quality(words, idx, config)
            scored_breaks.append((idx, score))
        
        # 3. é€‰æ‹©æœ€ä½³æ–­ç‚¹ï¼ˆè€ƒè™‘è¯­ä¹‰è¿è´¯æ€§ï¼‰
        best_break = self._select_best_break(scored_breaks)
        
        # 4. æ‰§è¡Œæ–­å¥
        return self._break_at_index(words, best_break)
```

#### 2.2 å®ç°å¹³è¡¡å…œåº•ç­–ç•¥
```python
class BalancedFallbackStrategy(BreakStrategy):
    """å¹³è¡¡å…œåº•ç­–ç•¥ï¼ˆæ›¿ä»£ç®€å•å¹³å‡åˆ†å‰²ï¼‰"""
    
    def break_segments(self, words, config):
        # 1. å°è¯•åœ¨è¯­ä¹‰è¾¹ç•Œå¤„æ–­å¥ï¼ˆä¸ä½¿ç”¨spacyï¼‰
        semantic_breaks = self._find_semantic_boundaries(words)
        
        # 2. å¦‚æœæ²¡æœ‰è¯­ä¹‰è¾¹ç•Œï¼Œä½¿ç”¨å¹³è¡¡ç®—æ³•
        if not semantic_breaks:
            return self._balanced_break_by_limits(words, config)
        
        # 3. é€‰æ‹©æœ€å¹³è¡¡çš„è¯­ä¹‰è¾¹ç•Œ
        return self._select_most_balanced_break(words, semantic_breaks, config)
```

### é˜¶æ®µä¸‰ï¼šspacyè¯­ä¹‰æ–­å¥é›†æˆ (é¢„è®¡4-5å¤©)

#### 3.1 å®ç°spacyåŒ…è£…å™¨ï¼ˆå¯é€‰ä¾èµ–ï¼‰
```python
# services/common/subtitle/semantic_breaker.py
try:
    import spacy
    SPACY_AVAILABLE = True
except ImportError:
    SPACY_AVAILABLE = False

class SemanticBreaker:
    """è¯­ä¹‰æ–­å¥å™¨ï¼ˆspacyåŒ…è£…ï¼‰"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.models = {}
        self._load_models()
    
    def _load_models(self):
        """æŒ‰éœ€åŠ è½½spacyæ¨¡å‹"""
        if not SPACY_AVAILABLE:
            return
        
        for lang, model_name in self.config.get('spacy_models', {}).items():
            try:
                self.models[lang] = spacy.load(model_name)
            except Exception as e:
                logger.warning(f"Failed to load spacy model {model_name}: {e}")
    
    def detect_language(self, text: str) -> str:
        """ç®€å•è¯­è¨€æ£€æµ‹"""
        # åŸºäºå­—ç¬¦åˆ†å¸ƒçš„è¯­è¨€æ£€æµ‹
        chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
        latin_chars = sum(1 for c in text if 'a' <= c.lower() <= 'z')
        
        if chinese_chars > latin_chars:
            return 'zh'
        elif latin_chars > chinese_chars:
            return 'en'
        else:
            return 'unknown'
    
    def break_by_semantics(self, words: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """ä½¿ç”¨spacyè¿›è¡Œè¯­ä¹‰æ–­å¥"""
        if not SPACY_AVAILABLE:
            return []
        
        # 1. åˆå¹¶æ–‡æœ¬å¹¶æ£€æµ‹è¯­è¨€
        text = self._words_to_text(words)
        lang = self.detect_language(text)
        
        if lang not in self.models:
            return []
        
        # 2. ä½¿ç”¨spacyåˆ†æå¥å­è¾¹ç•Œ
        doc = self.models[lang](text)
        sentence_boundaries = []
        
        for sent in doc.sents:
            start_char = sent.start_char
            end_char = sent.end_char
            # å°†å­—ç¬¦ä½ç½®æ˜ å°„å›è¯ç´¢å¼•
            word_indices = self._map_char_to_word_index(words, start_char, end_char)
            if word_indices:
                sentence_boundaries.append(word_indices)
        
        # 3. æŒ‰å¥å­è¾¹ç•Œåˆ†å‰²è¯åˆ—è¡¨
        return self._split_words_by_boundaries(words, sentence_boundaries)
```

#### 3.2 å®ç°è¯­ä¹‰æ–­å¥ç­–ç•¥
```python
class SemanticBreakStrategy(BreakStrategy):
    """è¯­ä¹‰æ–­å¥ç­–ç•¥"""
    
    def __init__(self):
        self.semantic_breaker = SemanticBreaker()
        self.rule_based_breaker = RuleBasedSemanticBreaker()  # è§„åˆ™å›é€€
    
    def can_handle(self, words, config):
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯­ä¹‰æ–­å¥
        semantic_config = config.get('semantic', {})
        if not semantic_config.get('enabled', False):
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„å†…å®¹è¿›è¡Œè¯­ä¹‰åˆ†æ
        return len(words) >= 3
    
    def break_segments(self, words, config):
        # å°è¯•ä½¿ç”¨spacy
        if config.get('semantic', {}).get('use_spacy', False):
            segments = self.semantic_breaker.break_by_semantics(words)
            if segments:
                return segments
        
        # å›é€€åˆ°è§„åˆ™è¯­ä¹‰æ–­å¥
        if config.get('semantic', {}).get('fallback_to_rules', True):
            return self.rule_based_breaker.break_by_rules(words, config)
        
        return []  # æ— æ³•å¤„ç†
```

### é˜¶æ®µå››ï¼šé›†æˆä¸é€‚é… (é¢„è®¡2-3å¤©)

#### 4.1 ä¿®æ”¹ç°æœ‰æ–­å¥å‡½æ•°
```python
# ä¿®æ”¹ services/common/subtitle/word_level_aligner.py

def rebuild_segments_by_words(
    segments: List[Dict[str, Any]],
    max_cpl: int = 42,
    max_cps: float = 18.0,
    min_duration: float = 1.0,
    max_duration: float = 7.0
) -> List[Dict[str, Any]]:
    """é‡æ„ç‰‡æ®µï¼ˆä½¿ç”¨æ–°ç­–ç•¥ï¼‰"""
    # 1. å±•å¹³è¯åˆ—è¡¨ï¼ˆä¿æŒä¸å˜ï¼‰
    words = _flatten_segment_words(segments)
    
    # 2. åŠ è½½é…ç½®
    config = load_breaking_config()
    config['limits'] = {
        'max_cpl': max_cpl,
        'max_cps': max_cps,
        'min_duration': min_duration,
        'max_duration': max_duration
    }
    
    # 3. ä½¿ç”¨ç­–ç•¥ç®¡ç†å™¨æ–­å¥
    strategy_manager = BreakStrategyManager(config)
    word_segments = strategy_manager.execute(words)
    
    # 4. æ„å»ºæœ€ç»ˆç‰‡æ®µ
    rebuilt_segments = []
    for word_group in word_segments:
        segment = _build_segment_from_words(word_group)
        rebuilt_segments.append(segment)
    
    return rebuilt_segments
```

#### 4.2 æ·»åŠ é…ç½®åŠ è½½
```python
def load_breaking_config() -> Dict:
    """åŠ è½½æ–­å¥é…ç½®"""
    default_config = {
        'enabled': True,
        'strategies': {
            'strong_punctuation': {'enabled': True},
            'semantic': {'enabled': False, 'use_spacy': False},
            'weak_punctuation': {'enabled': True},
            'balanced_fallback': {'enabled': True}
        }
    }
    
    # å°è¯•ä»é…ç½®æ–‡ä»¶åŠ è½½
    config_path = "/app/config/subtitle_breaking.yml"
    if os.path.exists(config_path):
        try:
            import yaml
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = yaml.safe_load(f)
                # æ·±åº¦åˆå¹¶é…ç½®
                return deep_merge(default_config, user_config)
        except Exception as e:
            logger.warning(f"Failed to load breaking config: {e}")
    
    return default_config
```

## ğŸ§ª æµ‹è¯•éªŒè¯è®¡åˆ’

### å•å…ƒæµ‹è¯•
```python
# tests/unit/common/subtitle/test_break_strategies.py

def test_strong_punctuation_strategy():
    """æµ‹è¯•å¼ºæ ‡ç‚¹ç­–ç•¥"""
    words = [{"word": "Hello.", "start": 0}, {"word": "World", "start": 1}]
    strategy = StrongPunctuationStrategy()
    result = strategy.break_segments(words, {})
    assert len(result) == 2  # åº”è¯¥åœ¨å¥å·å¤„æ–­å¥

def test_semantic_strategy_without_spacy():
    """æµ‹è¯•æ— spacyæ—¶çš„è¯­ä¹‰ç­–ç•¥å›é€€"""
    words = [{"word": "This", "start": 0}, {"word": "is", "start": 1}, 
             {"word": "a", "start": 2}, {"word": "test.", "start": 3}]
    strategy = SemanticBreakStrategy()
    result = strategy.break_segments(words, {'semantic': {'enabled': True, 'use_spacy': False}})
    assert result is not None

def test_multilingual_breaking():
    """æµ‹è¯•å¤šè¯­è¨€æ–­å¥"""
    # ä¸­æ–‡æµ‹è¯•
    chinese_words = [{"word": "è¿™æ˜¯", "start": 0}, {"word": "æµ‹è¯•ã€‚", "start": 1},
                     {"word": "è¿™æ˜¯", "start": 2}, {"word": "å¦ä¸€ä¸ª", "start": 3}]
    
    # è‹±æ–‡æµ‹è¯•
    english_words = [{"word": "This", "start": 0}, {"word": "is", "start": 1},
                     {"word": "a", "start": 2}, {"word": "test.", "start": 3}]
    
    # éªŒè¯ä¸¤ç§è¯­è¨€éƒ½èƒ½æ­£ç¡®å¤„ç†
```

### é›†æˆæµ‹è¯•
```python
# tests/integration/test_subtitle_breaking.py

def test_end_to_end_breaking():
    """ç«¯åˆ°ç«¯æ–­å¥æµ‹è¯•"""
    # æ¨¡æ‹ŸçœŸå®å·¥ä½œæµ
    input_segments = load_test_segments("multilingual_sample.json")
    result = rebuild_segments_by_words(input_segments)
    
    # éªŒè¯ç»“æœè´¨é‡
    assert all_limits_satisfied(result)  # æ£€æŸ¥æ‰€æœ‰é™åˆ¶
    assert semantic_coherence_improved(result)  # è¯­ä¹‰è¿è´¯æ€§æå‡
    
def test_backward_compatibility():
    """å‘åå…¼å®¹æ€§æµ‹è¯•"""
    # ä½¿ç”¨æ—§é…ç½®ï¼ˆç¦ç”¨æ–°åŠŸèƒ½ï¼‰
    old_config = {'enabled': False}
    old_result = rebuild_segments_with_config(test_data, old_config)
    
    # ä½¿ç”¨æ–°é…ç½®ï¼ˆä»…åŸºæœ¬åŠŸèƒ½ï¼‰
    new_config = {'enabled': True, 'strategies': {'semantic': {'enabled': False}}}
    new_result = rebuild_segments_with_config(test_data, new_config)
    
    # ç»“æœåº”è¯¥åŸºæœ¬ä¸€è‡´
    assert similar_enough(old_result, new_result)
```

### è´¨é‡è¯„ä¼°æµ‹è¯•
```bash
# è´¨é‡è¯„ä¼°è„šæœ¬
#!/bin/bash
# evaluate_breaking_quality.sh

echo "=== æ–­å¥è´¨é‡è¯„ä¼° ==="

# 1. è¯­ä¹‰è¿è´¯æ€§æµ‹è¯•
python -m tests.evaluate.semantic_coherence \
  --input samples/multilingual_corpus.json \
  --config config/subtitle_breaking.yml

# 2. å¤šè¯­è¨€æ”¯æŒæµ‹è¯•
python -m tests.evaluate.multilingual_support \
  --languages zh en ja ko \
  --samples-per-lang 50

# 3. æ€§èƒ½åŸºå‡†æµ‹è¯•
python -m tests.benchmark.breaking_performance \
  --iterations 100 \
  --sample-size large

# 4. å›å½’æµ‹è¯•
python -m tests.regression.breaking_regression \
  --baseline v1.0 \
  --current HEAD
```

## ğŸš€ éƒ¨ç½²è®¡åˆ’

### é˜¶æ®µéƒ¨ç½²ç­–ç•¥

#### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¶æ„éƒ¨ç½² (ç¬¬1å‘¨)
- éƒ¨ç½²ç­–ç•¥æ¥å£å’ŒåŸºç±»
- å°è£…ç°æœ‰é€»è¾‘ä¸ºç­–ç•¥
- æ·»åŠ é…ç½®ç³»ç»Ÿï¼ˆé»˜è®¤ç¦ç”¨æ–°åŠŸèƒ½ï¼‰
- **é£é™©**ï¼šä½ï¼Œä»…é‡æ„ä»£ç ç»“æ„

#### ç¬¬äºŒé˜¶æ®µï¼šå¢å¼ºè§„åˆ™éƒ¨ç½² (ç¬¬2å‘¨)
- éƒ¨ç½²å¢å¼ºçš„å¼±æ ‡ç‚¹ç­–ç•¥
- éƒ¨ç½²å¹³è¡¡å…œåº•ç­–ç•¥
- å¯ç”¨åŸºæœ¬æ–°åŠŸèƒ½ï¼ˆå…³é—­è¯­ä¹‰æ–­å¥ï¼‰
- **é£é™©**ï¼šä¸­ï¼Œæ”¹å˜æ–­å¥è¡Œä¸ºä½†å¯å›æ»š

#### ç¬¬ä¸‰é˜¶æ®µï¼šå¯é€‰åŠŸèƒ½éƒ¨ç½² (ç¬¬3å‘¨)
- éƒ¨ç½²spacyé›†æˆï¼ˆä½œä¸ºå¯é€‰ä¾èµ–ï¼‰
- æ·»åŠ è¯­è¨€æ£€æµ‹åŠŸèƒ½
- æä¾›é…ç½®å¼€å…³ï¼Œé»˜è®¤å…³é—­
- **é£é™©**ï¼šä½ï¼Œç”¨æˆ·éœ€æ˜¾å¼å¯ç”¨

#### ç¬¬å››é˜¶æ®µï¼šå…¨é¢å¯ç”¨ (ç¬¬4å‘¨)
- æ ¹æ®æµ‹è¯•ç»“æœè°ƒæ•´å‚æ•°
- é€æ­¥å¯ç”¨è¯­ä¹‰æ–­å¥åŠŸèƒ½
- ç›‘æ§ç”Ÿäº§ç¯å¢ƒæ•ˆæœ
- **é£é™©**ï¼šä¸­ï¼Œå¯†åˆ‡ç›‘æ§

### ç›‘æ§ä¸å›æ»š

#### ç›‘æ§æŒ‡æ ‡
```yaml
monitoring:
  metrics:
    - breaking_quality_score
    - semantic_coherence_ratio
    - processing_time_95th_percentile
    - failure_rate_by_language
  alerts:
    - breaking_quality_drop_10_percent
    - processing_time_increase_50_percent
    - failure_rate_above_5_percent
```

#### å›æ»šæœºåˆ¶
```bash
# å¿«é€Ÿå›æ»šè„šæœ¬
#!/bin/bash
# rollback_breaking_changes.sh

echo "å›æ»šæ–­å¥åŠŸèƒ½å˜æ›´..."

# 1. æ¢å¤é…ç½®æ–‡ä»¶
cp config/subtitle_breaking.yml.backup config/subtitle_breaking.yml

# 2. ç¦ç”¨æ–°åŠŸèƒ½
sed -i 's/enabled: true/enabled: false/' config/subtitle_breaking.yml

# 3. é‡å¯æœåŠ¡
docker compose restart wservice

echo "å›æ»šå®Œæˆï¼Œå·²æ¢å¤è‡³åŸå§‹æ–­å¥é€»è¾‘"
```

## ğŸ“Š æˆåŠŸæ ‡å‡†ä¸éªŒæ”¶

### æŠ€æœ¯éªŒæ”¶æ ‡å‡†
1. âœ… æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
2. âœ… é›†æˆæµ‹è¯•é€šè¿‡ç‡ â‰¥ 95%
3. âœ… æ€§èƒ½å½±å“ â‰¤ 20%
4. âœ… å†…å­˜ä½¿ç”¨å¢åŠ  â‰¤ 10%
5. âœ… å‘åå…¼å®¹æ€§éªŒè¯é€šè¿‡

### è´¨é‡éªŒæ”¶æ ‡å‡†
1. âœ… è¯­ä¹‰ä¸åˆç†æ–­å¥å‡å°‘ â‰¥ 30%
2. âœ… å¤šè¯­è¨€æ”¯æŒæµ‹è¯•é€šè¿‡
3. âœ… ç”¨æˆ·æ»¡æ„åº¦è°ƒæŸ¥æå‡
4. âœ… ç”Ÿäº§ç¯å¢ƒé”™è¯¯ç‡ä¸å¢åŠ 

### ä¸šåŠ¡éªŒæ”¶æ ‡å‡†
1. âœ… ä¸å½±å“ç°æœ‰å·¥ä½œæµ
2. âœ… é…ç½®çµæ´»ï¼Œæ»¡è¶³ä¸åŒåœºæ™¯
3. âœ… æ–‡æ¡£å®Œæ•´ï¼Œæ˜“äºä½¿ç”¨
4. âœ… ç»´æŠ¤æˆæœ¬å¯æ§

## ğŸ“ æ–‡æ¡£ä¸åŸ¹è®­

### å¼€å‘æ–‡æ¡£
- æ¶æ„è®¾è®¡æ–‡æ¡£
- APIæ¥å£æ–‡æ¡£
- é…ç½®è¯´æ˜æ–‡æ¡£
- æ‰©å±•å¼€å‘æŒ‡å—

### ç”¨æˆ·æ–‡æ¡£
- åŠŸèƒ½ç‰¹æ€§ä»‹ç»
- é…ç½®å‚æ•°è¯´æ˜
- æ•…éšœæ’é™¤æŒ‡å—
- æœ€ä½³å®è·µç¤ºä¾‹

### åŸ¹è®­ææ–™
- æ–°åŠŸèƒ½æ¼”ç¤º
- é…ç½®è°ƒä¼˜åŸ¹è®­
- é—®é¢˜è¯Šæ–­åŸ¹è®­
- æ‰©å±•å¼€å‘åŸ¹è®­

## ğŸ”® æœªæ¥æ‰©å±•è§„åˆ’

### çŸ­æœŸæ‰©å±• (3ä¸ªæœˆå†…)
1. æ”¯æŒæ›´å¤šè¯­è¨€ï¼ˆæ—¥è¯­ã€éŸ©è¯­ç­‰ï¼‰
2. æ·»åŠ è‡ªå®šä¹‰è§„åˆ™å¼•æ“
3. å®ç°æœºå™¨å­¦ä¹ ä¼˜åŒ–

### ä¸­æœŸæ‰©å±• (6ä¸ªæœˆå†…)
1. å®æ—¶æ–­å¥è´¨é‡è¯„ä¼°
2. è‡ªé€‚åº”å‚æ•°è°ƒæ•´
3. ç”¨æˆ·åé¦ˆå­¦ä¹ 

### é•¿æœŸæ„¿æ™¯ (1å¹´å†…)
1. ç«¯åˆ°ç«¯æ™ºèƒ½å­—å¹•ä¼˜åŒ–
2. ä¸ªæ€§åŒ–æ–­å¥é£æ ¼
3. è·¨è¯­è¨€ç»Ÿä¸€å¤„ç†æ¡†æ¶

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**åˆ›å»ºæ—¥æœŸ**: 2026å¹´1æœˆ29æ—¥  
**æœ€åæ›´æ–°**: 2026å¹´1æœˆ29æ—¥  
**è´Ÿè´£äºº**: å­—å¹•ä¼˜åŒ–é¡¹ç›®ç»„