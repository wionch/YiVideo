<<<<<<< HEAD
# Faster Whisper Service è¯­éŸ³è¯†åˆ«æœåŠ¡æ–‡æ¡£

> ðŸ§­ **å¯¼èˆª**: [YiVideoé¡¹ç›®æ ¹](/mnt/d/WSL2/docker/YiVideo/CLAUDE.md) > [Workersç›®å½•](/mnt/d/WSL2/docker/YiVideo/services/workers/) > **faster_whisper_service**

## æœåŠ¡æ¦‚è¿°

Faster Whisper Serviceæ˜¯åŸºäºŽfaster-whisperé«˜ç‰ˆæœ¬çš„è¯­éŸ³è¯†åˆ«(ASR)æœåŠ¡ï¼Œæä¾›GPUåŠ é€Ÿçš„å®žæ—¶è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½ã€‚è¯¥æœåŠ¡æ”¯æŒè¯çº§æ—¶é—´æˆ³ã€è¯´è¯äººåˆ†ç¦»é›†æˆå’Œå­—å¹•æ ¡æ­£ä¼˜åŒ–ã€‚

## æ ¸å¿ƒåŠŸèƒ½

- **è¯­éŸ³è¯†åˆ«**: å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—
- **è¯çº§æ—¶é—´æˆ³**: æä¾›ç²¾ç¡®çš„è¯çº§åˆ«æ—¶é—´æˆ³
- **GPUåŠ é€Ÿ**: ä½¿ç”¨faster-whisperå®žçŽ°é«˜é€ŸæŽ¨ç†
- **å­—å¹•ç”Ÿæˆ**: æ”¯æŒSRTã€VTTç­‰å­—å¹•æ ¼å¼
- **è¯´è¯äººåˆ†ç¦»**: ä¸Žpyannote_audio_serviceé›†æˆ
- **å­—å¹•æ ¡æ­£**: ä½¿ç”¨AIè¿›è¡Œå­—å¹•ä¼˜åŒ–

## ç›®å½•ç»“æž„

```
services/workers/faster_whisper_service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ celery_app.py           # Celeryåº”ç”¨é…ç½®
â”‚   â”œâ”€â”€ faster_whisper_infer.py # WhisperæŽ¨ç†å¼•æ“Ž
â”‚   â”œâ”€â”€ model_manager.py        # æ¨¡åž‹ç®¡ç†å™¨
â”‚   â”œâ”€â”€ speaker_word_matcher.py # è¯´è¯äººè¯åŒ¹é…å™¨
â”‚   â”œâ”€â”€ subtitle_merger.py      # å­—å¹•åˆå¹¶å™¨
â”‚   â”œâ”€â”€ tts_merger.py          # TTSåˆå¹¶å™¨
â”‚   â””â”€â”€ tasks.py               # Celeryä»»åŠ¡å®šä¹‰
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

## æ ¸å¿ƒæ–‡ä»¶

### tasks.py
- **ä¸»è¦ä»»åŠ¡**:
  - `speech_recognition()`: è¯­éŸ³è¯†åˆ«ä»»åŠ¡
  - ä½¿ç”¨`@gpu_lock`è£…é¥°å™¨ä¿æŠ¤GPUèµ„æº
  - æ”¯æŒè¯çº§æ—¶é—´æˆ³å’Œè¯´è¯äººåˆ†ç¦»
  - é›†æˆå­—å¹•æ ¡æ­£å’Œåˆå¹¶åŠŸèƒ½

### faster_whisper_infer.py
- **åŠŸèƒ½**: WhisperæŽ¨ç†å¼•æ“Ž
- **ç‰¹æ€§**:
  - æ¨¡åž‹åŠ è½½å’Œç®¡ç†
  - GPUå†…å­˜ä¼˜åŒ–
  - æ‰¹å¤„ç†æ”¯æŒ

### model_manager.py
- **åŠŸèƒ½**: æ¨¡åž‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **ç‰¹æ€§**:
  - æ¨¡åž‹ä¸‹è½½å’Œç¼“å­˜
  - æ¨¡åž‹ç‰ˆæœ¬ç®¡ç†
  - å†…å­˜ç®¡ç†

### subtitle_merger.py
- **åŠŸèƒ½**: å­—å¹•åˆå¹¶å’Œä¼˜åŒ–
- **ç±»**:
  - `SubtitleMerger`: é€šç”¨å­—å¹•åˆå¹¶
  - `WordLevelMerger`: è¯çº§åˆå¹¶å™¨
  - `create_subtitle_merger()`: åˆ›å»ºåˆå¹¶å™¨å·¥åŽ‚
  - `validate_speaker_segments()`: éªŒè¯è¯´è¯äººç‰‡æ®µ

## ä¾èµ–

```
celery==5.3.4
redis==5.0.1
faster-whisper>=1.1.1
torch>=2.0.0
numpy>=1.24.0
pyyaml>=6.0
pydantic
librosa
psutil
aiohttp
```

## GPUè¦æ±‚

- **å¿…éœ€**: æ”¯æŒCUDAçš„GPU
- **æŽ¨è**: NVIDIA RTXç³»åˆ—GPUï¼Œæ˜¾å­˜â‰¥8GB
- **CUDAç‰ˆæœ¬**: 11.xæˆ–æ›´é«˜

## ä»»åŠ¡æŽ¥å£

### æ ‡å‡†ä»»åŠ¡æŽ¥å£
```python
@celery_app.task(bind=True)
@gpu_lock(timeout=1800, poll_interval=0.5)
def speech_recognition(self, context):
    """
    è¯­éŸ³è¯†åˆ«ä»»åŠ¡

    Args:
        context: å·¥ä½œæµä¸Šä¸‹æ–‡ï¼ŒåŒ…å«:
            - audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            - language: è¯­è¨€ä»£ç 
            - model_size: æ¨¡åž‹å¤§å°
            - compute_type: è®¡ç®—ç±»åž‹

    Returns:
        æ›´æ–°åŽçš„context
    """
    pass
```

## é…ç½®å‚æ•°

- **æ¨¡åž‹å¤§å°**: tiny, base, small, medium, large
- **è®¡ç®—ç±»åž‹**: float16, int8, int8_float16
- **æ‰¹å¤„ç†å¤§å°**: å¯é…ç½®
- **è®¾å¤‡**: cuda:0, cpu

## å…±äº«å­˜å‚¨

- **è¾“å…¥**: `/share/workflows/{workflow_id}/audio/`
- **è¾“å‡º**: `/share/workflows/{workflow_id}/subtitles/`
- **ä¸­é—´æ–‡ä»¶**: `/share/workflows/{workflow_id}/temp/`

## ç›‘æŽ§

- **æ—¥å¿—**: ä½¿ç”¨`services.common.logger`
- **çŠ¶æ€**: é€šè¿‡`state_manager`æ›´æ–°
- **GPUç›‘æŽ§**: é›†æˆGPUé”ç³»ç»Ÿ

## é›†æˆæœåŠ¡

- **è¯´è¯äººåˆ†ç¦»**: `pyannote_audio_service`
- **å­—å¹•ä¼˜åŒ–**: `services.common.subtitle.*`
- **çŠ¶æ€ç®¡ç†**: `services.common.state_manager`
- **GPUé”**: `services.common.locks`

## æ€§èƒ½ä¼˜åŒ–

1. **æ¨¡åž‹é‡åŒ–**: æ”¯æŒint8é‡åŒ–å‡å°‘æ˜¾å­˜å ç”¨
2. **æ‰¹å¤„ç†**: æ”¯æŒæ‰¹é‡æŽ¨ç†æé«˜åžåé‡
3. **GPUå†…å­˜ç®¡ç†**: è‡ªåŠ¨æ¸…ç†å’Œç›‘æŽ§
4. **æ¨¡åž‹ç¼“å­˜**: é¿å…é‡å¤åŠ è½½æ¨¡åž‹

## æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   - å‡å°æ¨¡åž‹å¤§å°
   - å¯ç”¨é‡åŒ–
   - å‡å°‘æ‰¹å¤„ç†å¤§å°

2. **æ¨¡åž‹åŠ è½½å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿žæŽ¥
   - éªŒè¯HuggingFace token
   - æ£€æŸ¥ç£ç›˜ç©ºé—´

3. **æŽ¨ç†é€Ÿåº¦æ…¢**
   - æ£€æŸ¥GPUåˆ©ç”¨çŽ‡
   - è°ƒæ•´æ‰¹å¤„ç†å¤§å°
   - ä¼˜åŒ–æ¨¡åž‹å‚æ•°

## ç›¸å…³æ–‡æ¡£

- [faster-whisperå®˜æ–¹æ–‡æ¡£](https://github.com/guillaumekln/faster-whisper)
- [GPUé”æ–‡æ¡£](/mnt/d/WSL2/docker/YiVideo/services/common/CLAUDE.md#gpué”ç³»ç»Ÿ)
- [çŠ¶æ€ç®¡ç†æ–‡æ¡£](/mnt/d/WSL2/docker/YiVideo/services/common/CLAUDE.md#çŠ¶æ€ç®¡ç†)
=======
# Faster Whisper Service è¯­éŸ³è¯†åˆ«æœåŠ¡æ–‡æ¡£

> ðŸ§­ **å¯¼èˆª**: [YiVideoé¡¹ç›®æ ¹](/mnt/d/WSL2/docker/YiVideo/CLAUDE.md) > [Workersç›®å½•](/mnt/d/WSL2/docker/YiVideo/services/workers/) > **faster_whisper_service**

## æœåŠ¡æ¦‚è¿°

Faster Whisper Serviceæ˜¯åŸºäºŽfaster-whisperé«˜ç‰ˆæœ¬çš„è¯­éŸ³è¯†åˆ«(ASR)æœåŠ¡ï¼Œæä¾›GPUåŠ é€Ÿçš„å®žæ—¶è¯­éŸ³è½¬æ–‡å­—åŠŸèƒ½ã€‚è¯¥æœåŠ¡ä¸“æ³¨äºŽGPUæŽ¨ç†ï¼Œä»…è´Ÿè´£è¯­éŸ³è½¬å½•ï¼Œç”Ÿæˆå¸¦è¯çº§æ—¶é—´æˆ³çš„è½¬å½•æ•°æ®ã€‚

## æ ¸å¿ƒåŠŸèƒ½

- **è¯­éŸ³è¯†åˆ«**: å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡å­—ï¼ˆGPUåŠ é€Ÿï¼‰
- **è¯çº§æ—¶é—´æˆ³**: æä¾›ç²¾ç¡®çš„è¯çº§åˆ«æ—¶é—´æˆ³
- **GPUåŠ é€Ÿ**: ä½¿ç”¨faster-whisperå®žçŽ°é«˜é€ŸæŽ¨ç†
- **æ¨¡åž‹ç®¡ç†**: è‡ªåŠ¨ä¸‹è½½ã€ç¼“å­˜å’Œç®¡ç†æ¨¡åž‹
- **å†…å­˜ä¼˜åŒ–**: GPUæ˜¾å­˜ç®¡ç†å’Œä¼˜åŒ–

## è¿ç§»è¯´æ˜Ž

éžGPUå­—å¹•å¤„ç†åŠŸèƒ½å·²è¿ç§»è‡³`wservice`æœåŠ¡ï¼ŒåŒ…æ‹¬ï¼š
- å­—å¹•æ–‡ä»¶ç”Ÿæˆ
- è¯´è¯äººç‰‡æ®µåˆå¹¶
- è¯çº§æ—¶é—´æˆ³åˆå¹¶
- å­—å¹•AIæ ¡æ­£

## ç›®å½•ç»“æž„

```
services/workers/faster_whisper_service/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ celery_app.py           # Celeryåº”ç”¨é…ç½®
â”‚   â”œâ”€â”€ faster_whisper_infer.py # WhisperæŽ¨ç†å¼•æ“Ž
â”‚   â”œâ”€â”€ model_manager.py        # æ¨¡åž‹ç®¡ç†å™¨
â”‚   â”œâ”€â”€ speaker_word_matcher.py # è¯´è¯äººè¯åŒ¹é…å™¨
â”‚   â”œâ”€â”€ subtitle_merger.py      # å­—å¹•åˆå¹¶å™¨
â”‚   â”œâ”€â”€ tts_merger.py          # TTSåˆå¹¶å™¨
â”‚   â””â”€â”€ tasks.py               # Celeryä»»åŠ¡å®šä¹‰
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

## æ ¸å¿ƒæ–‡ä»¶

### tasks.py
- **ä¸»è¦ä»»åŠ¡**:
  - `transcribe_audio()`: è¯­éŸ³è¯†åˆ«ä»»åŠ¡ï¼ˆGPUæŽ¨ç†ï¼‰
  - ä½¿ç”¨GPUé”è£…é¥°å™¨ä¿æŠ¤GPUèµ„æº
  - æ”¯æŒè¯çº§æ—¶é—´æˆ³ç”Ÿæˆ
  - è¾“å‡ºæ ‡å‡†åŒ–è½¬å½•æ•°æ®ä¾›åŽç»­å­—å¹•å¤„ç†ä½¿ç”¨

### faster_whisper_infer.py
- **åŠŸèƒ½**: WhisperæŽ¨ç†å¼•æ“Ž
- **ç‰¹æ€§**:
  - æ¨¡åž‹åŠ è½½å’Œç®¡ç†
  - GPUå†…å­˜ä¼˜åŒ–
  - æ‰¹å¤„ç†æ”¯æŒ

### model_manager.py
- **åŠŸèƒ½**: æ¨¡åž‹ç”Ÿå‘½å‘¨æœŸç®¡ç†
- **ç‰¹æ€§**:
  - æ¨¡åž‹ä¸‹è½½å’Œç¼“å­˜
  - æ¨¡åž‹ç‰ˆæœ¬ç®¡ç†
  - å†…å­˜ç®¡ç†

### subtitle_merger.py
- **åŠŸèƒ½**: å­—å¹•åˆå¹¶å’Œä¼˜åŒ–
- **ç±»**:
  - `SubtitleMerger`: é€šç”¨å­—å¹•åˆå¹¶
  - `WordLevelMerger`: è¯çº§åˆå¹¶å™¨
  - `create_subtitle_merger()`: åˆ›å»ºåˆå¹¶å™¨å·¥åŽ‚
  - `validate_speaker_segments()`: éªŒè¯è¯´è¯äººç‰‡æ®µ

## ä¾èµ–

```
celery==5.3.4
redis==5.0.1
faster-whisper>=1.1.1
torch>=2.0.0
numpy>=1.24.0
pyyaml>=6.0
pydantic
librosa
psutil
aiohttp
```

## GPUè¦æ±‚

- **å¿…éœ€**: æ”¯æŒCUDAçš„GPU
- **æŽ¨è**: NVIDIA RTXç³»åˆ—GPUï¼Œæ˜¾å­˜â‰¥8GB
- **CUDAç‰ˆæœ¬**: 11.xæˆ–æ›´é«˜

## ä»»åŠ¡æŽ¥å£

### æ ‡å‡†ä»»åŠ¡æŽ¥å£
```python
@celery_app.task(bind=True)
@gpu_lock(timeout=1800, poll_interval=0.5)
def speech_recognition(self, context):
    """
    è¯­éŸ³è¯†åˆ«ä»»åŠ¡

    Args:
        context: å·¥ä½œæµä¸Šä¸‹æ–‡ï¼ŒåŒ…å«:
            - audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            - language: è¯­è¨€ä»£ç 
            - model_size: æ¨¡åž‹å¤§å°
            - compute_type: è®¡ç®—ç±»åž‹

    Returns:
        æ›´æ–°åŽçš„context
    """
    pass
```

## é…ç½®å‚æ•°

- **æ¨¡åž‹å¤§å°**: tiny, base, small, medium, large
- **è®¡ç®—ç±»åž‹**: float16, int8, int8_float16
- **æ‰¹å¤„ç†å¤§å°**: å¯é…ç½®
- **è®¾å¤‡**: cuda:0, cpu

## å…±äº«å­˜å‚¨

- **è¾“å…¥**: `/share/workflows/{workflow_id}/audio/`
- **è¾“å‡º**: `/share/workflows/{workflow_id}/transcribe_data.json`ï¼ˆè½¬å½•æ•°æ®ï¼‰
- **ä¸­é—´æ–‡ä»¶**: `/share/workflows/{workflow_id}/temp/`

## ç›‘æŽ§

- **æ—¥å¿—**: ä½¿ç”¨`services.common.logger`
- **çŠ¶æ€**: é€šè¿‡`state_manager`æ›´æ–°
- **GPUç›‘æŽ§**: é›†æˆGPUé”ç³»ç»Ÿ

## é›†æˆæœåŠ¡

- **ä¸‹æ¸¸å­—å¹•å¤„ç†**: `wservice`ï¼ˆæŽ¥æ”¶è½¬å½•æ•°æ®å¹¶ç”Ÿæˆå­—å¹•ï¼‰
- **çŠ¶æ€ç®¡ç†**: `services.common.state_manager`
- **GPUé”**: `services.common.locks`

## æ€§èƒ½ä¼˜åŒ–

1. **æ¨¡åž‹é‡åŒ–**: æ”¯æŒint8é‡åŒ–å‡å°‘æ˜¾å­˜å ç”¨
2. **æ‰¹å¤„ç†**: æ”¯æŒæ‰¹é‡æŽ¨ç†æé«˜åžåé‡
3. **GPUå†…å­˜ç®¡ç†**: è‡ªåŠ¨æ¸…ç†å’Œç›‘æŽ§
4. **æ¨¡åž‹ç¼“å­˜**: é¿å…é‡å¤åŠ è½½æ¨¡åž‹

## æ•…éšœæŽ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDAå†…å­˜ä¸è¶³**
   - å‡å°æ¨¡åž‹å¤§å°
   - å¯ç”¨é‡åŒ–
   - å‡å°‘æ‰¹å¤„ç†å¤§å°

2. **æ¨¡åž‹åŠ è½½å¤±è´¥**
   - æ£€æŸ¥ç½‘ç»œè¿žæŽ¥
   - éªŒè¯HuggingFace token
   - æ£€æŸ¥ç£ç›˜ç©ºé—´

3. **æŽ¨ç†é€Ÿåº¦æ…¢**
   - æ£€æŸ¥GPUåˆ©ç”¨çŽ‡
   - è°ƒæ•´æ‰¹å¤„ç†å¤§å°
   - ä¼˜åŒ–æ¨¡åž‹å‚æ•°

## ç›¸å…³æ–‡æ¡£

- [faster-whisperå®˜æ–¹æ–‡æ¡£](https://github.com/guillaumekln/faster-whisper)
- [GPUé”æ–‡æ¡£](/mnt/d/WSL2/docker/YiVideo/services/common/CLAUDE.md#gpué”ç³»ç»Ÿ)
- [çŠ¶æ€ç®¡ç†æ–‡æ¡£](/mnt/d/WSL2/docker/YiVideo/services/common/CLAUDE.md#çŠ¶æ€ç®¡ç†)
>>>>>>> 002-migrate-nongpu-nodes
