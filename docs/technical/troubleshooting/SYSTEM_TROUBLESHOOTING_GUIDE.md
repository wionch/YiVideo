# ç³»ç»Ÿé€šç”¨æ•…éšœæ’é™¤æŒ‡å—

## ç›®å½•

1. [å¿«é€Ÿè¯Šæ–­](#å¿«é€Ÿè¯Šæ–­)
2. [å¸¸è§é”™è¯¯ä»£ç ](#å¸¸è§é”™è¯¯ä»£ç )
3. [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)
4. [èµ„æºé—®é¢˜](#èµ„æºé—®é¢˜)
5. [ç½‘ç»œé—®é¢˜](#ç½‘ç»œé—®é¢˜)
6. [é…ç½®é—®é¢˜](#é…ç½®é—®é¢˜)
7. [è°ƒè¯•å·¥å…·](#è°ƒè¯•å·¥å…·)
8. [è”ç³»æ”¯æŒ](#è”ç³»æ”¯æŒ)

---

## å¿«é€Ÿè¯Šæ–­

### è¯Šæ–­æµç¨‹å›¾

```
å¼€å§‹
  â†“
æ£€æŸ¥æœåŠ¡çŠ¶æ€ â†’ æ­£å¸¸ â†’ æ£€æŸ¥å·¥ä½œæµæ‰§è¡Œ
  â†“                      â†“
å¼‚å¸¸                    æ­£å¸¸ â†’ é—®é¢˜è§£å†³
  â†“                      â†“
æ£€æŸ¥æ—¥å¿—æ–‡ä»¶            å¼‚å¸¸ â†’ æ£€æŸ¥è¾“å…¥æ•°æ®
  â†“                      â†“
ä¿®å¤é—®é¢˜                æ­£å¸¸ â†’ æ£€æŸ¥é…ç½®
  â†“                      â†“
é‡å¯æœåŠ¡                å¼‚å¸¸ â†’ æ£€æŸ¥ç¯å¢ƒ
  â†“                      â†“
éªŒè¯ä¿®å¤                ä¿®å¤ç¯å¢ƒ
  â†“                      â†“
é—®é¢˜è§£å†³                é‡å¯æœåŠ¡
```

### å¿«é€Ÿæ£€æŸ¥æ¸…å•

```bash
# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps
docker-compose logs --tail=50

# 2. æ£€æŸ¥ç³»ç»Ÿèµ„æº
nvidia-smi
free -h
df -h

# 3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ ¸å¿ƒæœåŠ¡
curl http://localhost:8788/health
docker-compose exec redis redis-cli ping

# 4. æ£€æŸ¥ GPU é”çŠ¶æ€
# æ³¨æ„: æ­£ç¡®çš„ç›‘æ§ç«¯ç‚¹è·¯å¾„ä¸º /api/v1/monitoring/gpu-lock/status
curl http://localhost:8788/api/v1/monitoring/gpu-lock/status
```

---

## å¸¸è§é”™è¯¯ä»£ç 

### API é”™è¯¯ (4xx/5xx)

#### 400 Bad Request

**é”™è¯¯ä¿¡æ¯**: "Bad Request: invalid input parameters"

**å¯èƒ½åŸå› **:
- è¯·æ±‚å‚æ•°æ ¼å¼é”™è¯¯
- ç¼ºå°‘å¿…éœ€å‚æ•°
- å‚æ•°å€¼ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥è¯·æ±‚æ ¼å¼å’Œå‚æ•°
curl -X POST http://localhost:8788/v1/workflows \
  -H "Content-Type: application/json" \
  -d '{"video_path": "/share/videos/input/example.mp4", "workflow_config": {}}'

# æç¤º: è¯·ä»”ç»†æ ¸å¯¹ workflow_config çš„ç»“æ„å’Œå‚æ•°
```

#### 401 Unauthorized

**é”™è¯¯ä¿¡æ¯**: "Unauthorized: invalid API key"

**å¯èƒ½åŸå› **:
- API å¯†é’¥æ— æ•ˆæˆ–ç¼ºå¤± (å¦‚æœå¯ç”¨äº†è®¤è¯)
- è®¤è¯é…ç½®é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ API å¯†é’¥é…ç½® (å¦‚æœ auth.enabled ä¸º true)
grep -r "auth:" config.yml
```

#### 404 Not Found

**é”™è¯¯ä¿¡æ¯**: "Not Found: workflow does not exist"

**å¯èƒ½åŸå› **:
- å·¥ä½œæµ ID ä¸å­˜åœ¨
- å·¥ä½œæµå·²è¿‡æœŸå¹¶è¢«æ¸…ç†

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥å·¥ä½œæµçŠ¶æ€
curl http://localhost:8788/v1/workflows/{workflow_id}
```

#### 500 Internal Server Error

**é”™è¯¯ä¿¡æ¯**: "Internal Server Error"

**å¯èƒ½åŸå› **:
- æœåŠ¡å™¨å†…éƒ¨é”™è¯¯
- æ•°æ®åº“è¿æ¥å¤±è´¥
- GPU èµ„æºä¸è¶³
- ASRæˆ–è¯´è¯äººåˆ†ç¦»æœåŠ¡å†…éƒ¨é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥è¯¦ç»†æ—¥å¿—
docker-compose logs --tail=100 api_gateway
docker-compose logs --tail=100 faster_whisper_service
docker-compose logs --tail=100 pyannote_audio_service

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
docker-compose exec redis redis-cli ping

# æ£€æŸ¥ GPU çŠ¶æ€
nvidia-smi

# æ£€æŸ¥ ASR æœåŠ¡çŠ¶æ€
docker exec faster_whisper_service celery -A app.celery_app inspect active

# æ£€æŸ¥è¯´è¯äººåˆ†ç¦»æœåŠ¡çŠ¶æ€
docker exec pyannote_audio_service celery -A app.celery_app inspect active
```

### ASR ä¸è¯´è¯äººåˆ†ç¦»æœåŠ¡ç‰¹å®šé”™è¯¯ (faster-whisper & pyannote)

#### æ¨¡å‹åŠ è½½é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: "Failed to load ASR/Diarization model"

**å¯èƒ½åŸå› **:
- ASR (Faster-Whisper) æˆ–è¯´è¯äººåˆ†ç¦» (Pyannote) æ¨¡å‹æ–‡ä»¶æŸå
- ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œæ— æ³•ä» Hugging Face ä¸‹è½½æ¨¡å‹
- æ˜¾å­˜ä¸è¶³

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶ (è·¯å¾„å–å†³äº config.yml)
# ls -la /path/to/your/model/cache/

# æ¸…ç†æ¨¡å‹ç¼“å­˜
# rm -rf /path/to/your/model/cache/*

# è§¦å‘æ¨¡å‹é‡æ–°ä¸‹è½½
docker-compose restart faster_whisper_service pyannote_audio_service
```

#### Hugging Face è®¤è¯é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: "Failed to download model from Hugging Face Hub" æˆ– "Authorization required" (é€šå¸¸æ¥è‡ª `pyannote_audio_service`)

**å¯èƒ½åŸå› **:
- HF_TOKEN ç¯å¢ƒå˜é‡æœªè®¾ç½®æˆ–æ— æ•ˆ
- use_auth_token å‚æ•°æœªæ­£ç¡®é…ç½®
- ç½‘ç»œè¿æ¥é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥ HF_TOKEN æ˜¯å¦é…ç½® (ä¸»è¦å½±å“ pyannote_audio_service)
docker exec pyannote_audio_service env | grep HF_TOKEN

# 2. å¦‚æœéœ€è¦ï¼Œé‡æ–°æ„å»ºå®¹å™¨
docker-compose build pyannote_audio_service --no-cache
docker-compose up -d pyannote_audio_service

# 3. éªŒè¯
docker-compose logs --tail=20 pyannote_audio_service
```


#### Faster-Whisper åç«¯é—®é¢˜

**é”™è¯¯ä¿¡æ¯**: "Faster-Whisper initialization failed" æˆ–æ€§èƒ½ä¸‹é™

**å¯èƒ½åŸå› **:
- ctranslate2 ç‰ˆæœ¬ä¸å…¼å®¹
- faster-whisper é…ç½®é”™è¯¯
- GPU é©±åŠ¨é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥ faster-whisper ä¾èµ–ç‰ˆæœ¬
docker exec faster_whisper_service pip list | grep -E "(faster-whisper|ctranslate2)"

# 2. éªŒè¯é…ç½®
grep -A 10 "faster_whisper" config.yml

# 3. æµ‹è¯•åŸç”Ÿåç«¯é™çº§

# 4. é‡å¯æœåŠ¡
docker-compose restart faster_whisper_service

# 5. æ€§èƒ½å¯¹æ¯”æµ‹è¯• (ç¤ºä¾‹)
# time python scripts/performance_benchmark.py --service faster_whisper
```

#### GPU å†…å­˜ä¸è¶³

**é”™è¯¯ä¿¡æ¯**: "CUDA out of memory"

**å¯èƒ½åŸå› **:
- æ‰¹å¤„ç†å¤§å°è¿‡å¤§
- æ¨¡å‹è¿‡å¤§
- å…¶ä»–è¿›ç¨‹å ç”¨æ˜¾å­˜

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ˜¾å­˜ä½¿ç”¨
nvidia-smi

# è°ƒæ•´æ‰¹å¤„ç†å¤§å°
# ç¼–è¾‘ config.yml
faster_whisper_service:
  batch_size: 2  # å‡å°æ‰¹å¤„ç†å¤§å°

# é‡å¯æœåŠ¡
docker-compose restart faster_whisper_service
```

#### éŸ³é¢‘å¤„ç†é”™è¯¯

**é”™è¯¯ä¿¡æ¯**: "Audio processing failed"

**å¯èƒ½åŸå› **:
- éŸ³é¢‘æ ¼å¼ä¸æ”¯æŒ
- éŸ³é¢‘æ–‡ä»¶æŸå
- FFmpeg ä¸å¯ç”¨

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥ FFmpeg (é€šå¸¸åœ¨ ffmpeg_service ä¸­)
docker-compose exec ffmpeg_service ffmpeg -version

# éªŒè¯éŸ³é¢‘æ–‡ä»¶
docker-compose exec ffmpeg_service ffprobe /app/videos/test.mp4

# é‡æ–°å®‰è£… FFmpeg
docker-compose build --no-cache ffmpeg_service
```

---

## æ€§èƒ½é—®é¢˜

### æ‰§è¡Œæ—¶é—´è¿‡é•¿

#### è¯Šæ–­æ­¥éª¤

```bash
# 1. æ£€æŸ¥ GPU åˆ©ç”¨ç‡
watch -n 1 nvidia-smi

# 2. æ£€æŸ¥ CPU ä½¿ç”¨
htop

# 3. æ£€æŸ¥ç£ç›˜ I/O
iostat -x 1

# 4. æ£€æŸ¥ç½‘ç»œå¸¦å®½
iftop

# 5. è¿è¡Œæ€§èƒ½åˆ†æ (ç¤ºä¾‹)
# (å¯ä½¿ç”¨ Prometheus/Grafana æˆ–è‡ªå®šä¹‰è„šæœ¬åˆ†æ)
```

#### ä¼˜åŒ–æ–¹æ¡ˆ

```yaml
# config.yml ä¼˜åŒ–
faster_whisper_service:
  batch_size: 4              # ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°
  compute_type: "float16"    # ä½¿ç”¨åŠç²¾åº¦
  use_faster_whisper: true    # å¯ç”¨ Faster-Whisper
  faster_whisper_threads: 4  # ä¼˜åŒ–çº¿ç¨‹æ•°

pipeline:
  detect_keyframes: true     # å¯ç”¨å…³é”®å¸§æ£€æµ‹
  use_image_concat: true     # å¯ç”¨å›¾åƒæ‹¼æ¥
```

### å†…å­˜æ³„æ¼

#### è¯Šæ–­æ­¥éª¤

```bash
# 1. ç›‘æ§å†…å­˜ä½¿ç”¨
watch -n 1 'free -h'

# 2. æ£€æŸ¥ Docker å®¹å™¨å†…å­˜
docker stats --format "table {{.Container}}\t{{.MemUsage}}"

# 3. åˆ†æå†…å­˜ä½¿ç”¨ (ç¤ºä¾‹)
# (å¯ä½¿ç”¨ pmap, valgrind,æˆ–è‡ªå®šä¹‰è„šæœ¬åˆ†æ)
```

#### è§£å†³æ–¹æ¡ˆ

```python
# æ·»åŠ å†…å­˜æ¸…ç†ä»£ç 
import torch
import gc

def cleanup_memory():
    """æ¸…ç†å†…å­˜"""
    torch.cuda.empty_cache()
    gc.collect()
```

### GPU åˆ©ç”¨ç‡ä½

#### è¯Šæ–­æ­¥éª¤

```bash
# 1. æ£€æŸ¥ GPU çŠ¶æ€
nvidia-smi dmon

# 2. æ£€æŸ¥ GPU è¿›ç¨‹
nvidia-smi pmon

# 3. æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°
# è°ƒæ•´ config.yml ä¸­çš„ batch_size

# 2. å¯ç”¨ GPU åŠ é€Ÿ
ç¡®ä¿ config.yml ä¸­ device: "cuda"

# 3. æ£€æŸ¥ GPU é©±åŠ¨
sudo nvidia-smi --query-gpu=driver_version,name --format=csv
```

---

## èµ„æºé—®é¢˜

### CPU èµ„æºä¸è¶³

#### è¯Šæ–­

```bash
# æ£€æŸ¥ CPU ä½¿ç”¨ç‡
top
htop

# æ£€æŸ¥ CPU æ ¸å¿ƒæ•°
nproc

# æ£€æŸ¥è¿›ç¨‹æ•°
ps aux | wc -l
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. é™åˆ¶è¿›ç¨‹æ•°
ulimit -u 4096

# 2. ä¼˜åŒ– CPU äº²å’Œæ€§
taskset -c 0,1,2,3 python script.py

# 3. å‡çº§ CPU æˆ–å¢åŠ æ ¸å¿ƒæ•°
```

### å†…å­˜ä¸è¶³

#### è¯Šæ–­

```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
cat /proc/meminfo

# æ£€æŸ¥å†…å­˜æ³„æ¼ (å¯ä½¿ç”¨ valgrind ç­‰å·¥å…·)
# valgrind --leak-check=full python script.py
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. å¢åŠ äº¤æ¢ç©ºé—´
sudo fallocate -l 4G /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile

# 2. ä¼˜åŒ–å†…å­˜ä½¿ç”¨
# è°ƒæ•´ config.yml ä¸­çš„å†…å­˜ç›¸å…³å‚æ•°

# 3. å¢åŠ ç‰©ç†å†…å­˜
```

### ç£ç›˜ç©ºé—´ä¸è¶³

#### è¯Šæ–­

```bash
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨
df -h
du -sh /app/*

# æŸ¥æ‰¾å¤§æ–‡ä»¶
find /app -type f -size +100M
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. æ¸…ç†æ—¥å¿—æ–‡ä»¶
find /logs -name "*.log" -mtime +7 -delete

# 2. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
find /tmp -name "*.tmp" -delete

# 3. æ¸…ç† Docker ç¼“å­˜
docker system prune -f

# 4. æ‰©å±•ç£ç›˜ç©ºé—´
```

---

## ç½‘ç»œé—®é¢˜

### è¿æ¥è¶…æ—¶

#### è¯Šæ–­

```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping 8.8.8.8

# æ£€æŸ¥ç«¯å£ç›‘å¬
netstat -tlnp | grep 8788

# æ£€æŸ¥é˜²ç«å¢™
sudo ufw status
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
sudo ufw allow 8788
sudo ufw allow 6379

# 2. é‡å¯ç½‘ç»œæœåŠ¡
sudo systemctl restart network

# 3. æ£€æŸ¥ DNS é…ç½®
cat /etc/resolv.conf
```

### Redis è¿æ¥é—®é¢˜

#### è¯Šæ–­

```bash
# æ£€æŸ¥ Redis çŠ¶æ€
docker-compose ps redis
docker-compose logs redis

# æµ‹è¯• Redis è¿æ¥
redis-cli -h redis -p 6379 ping
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. é‡å¯ Redis
docker-compose restart redis

# 2. æ£€æŸ¥ Redis é…ç½®
docker-compose exec redis redis-cli config get *

# 3. æ£€æŸ¥ç½‘ç»œè¿æ¥
docker-compose exec redis redis-cli info clients
```

### API é™æµ

#### è¯Šæ–­

```bash
# æ£€æŸ¥ API è¯·æ±‚é¢‘ç‡
curl -I http://localhost:8788/health

# æ£€æŸ¥é™æµé…ç½®
grep -r "rate_limit" config.yml
```

#### è§£å†³æ–¹æ¡ˆ

```yaml
# è°ƒæ•´é™æµé…ç½®
api_gateway:
  rate_limit:
    requests_per_minute: 100
    burst_size: 10
```

---

## é…ç½®é—®é¢˜

### é…ç½®æ–‡ä»¶é”™è¯¯

#### è¯Šæ–­

```bash
# éªŒè¯é…ç½®æ–‡ä»¶è¯­æ³• (ç¤ºä¾‹)
python -c "import yaml; yaml.safe_load(open('config.yml'))"
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. å¤‡ä»½å½“å‰é…ç½®
cp config.yml config.yml.backup

# 2. ä½¿ç”¨é»˜è®¤é…ç½®
# cp config.yml.default config.yml

# 3. æ‰‹åŠ¨æ£€æŸ¥å’Œä¿®å¤é…ç½®
# (å¯¹æ¯”å¤‡ä»½æ–‡ä»¶ï¼Œé€é¡¹æ£€æŸ¥)
```

### ç¯å¢ƒå˜é‡é—®é¢˜

#### è¯Šæ–­

```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
env | grep -i -E "(faster_whisper|pyannote)"

# æ£€æŸ¥ Docker ç¯å¢ƒå˜é‡
docker-compose exec api_gateway env
```

#### è§£å†³æ–¹æ¡ˆ

```bash
# 1. è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=0
# export OBSOLETE_WHISPERX_MODEL_PATH=/app/models

# 2. æ›´æ–° docker-compose.yml
environment:
  - CUDA_VISIBLE_DEVICES=0
  # - OBSOLETE_WHISPERX_MODEL_PATH=/app/models
```

---

## è°ƒè¯•å·¥å…·

### æ—¥å¿—åˆ†æå·¥å…·

```bash
# 1. å®æ—¶æ—¥å¿—ç›‘æ§
docker-compose logs -f --tail=100

# 2. é”™è¯¯æ—¥å¿—è¿‡æ»¤
docker-compose logs 2>&1 | grep -i error

# 3. æ€§èƒ½æ—¥å¿—åˆ†æ
docker-compose logs faster_whisper_service | grep "execution_time"
```

### æ€§èƒ½åˆ†æå·¥å…·

```python
# æ€§èƒ½åˆ†æè„šæœ¬
import time
import psutil
import torch

def analyze_performance():
    """åˆ†æç³»ç»Ÿæ€§èƒ½"""
    print("=== æ€§èƒ½åˆ†ææŠ¥å‘Š ===")
    print(f"CPU ä½¿ç”¨ç‡: {psutil.cpu_percent()}%")
    print(f"å†…å­˜ä½¿ç”¨ç‡: {psutil.virtual_memory().percent}%")

    if torch.cuda.is_available():
        print(f"GPU æ˜¾å­˜ä½¿ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
        print(f"GPU åˆ©ç”¨ç‡: {get_gpu_utilization()}%")

def get_gpu_utilization():
    """è·å– GPU åˆ©ç”¨ç‡"""
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=utilization.gpu', '--format=csv,noheader,nounits'],
            capture_output=True, text=True
        )
        return float(result.stdout.strip())
    except:
        return 0.0
```

### å¥åº·æ£€æŸ¥å·¥å…·

```bash
#!/bin/bash
# å¥åº·æ£€æŸ¥è„šæœ¬

echo "=== ç³»ç»Ÿå¥åº·æ£€æŸ¥ ==="

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "1. æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose ps

# æ£€æŸ¥ API å¥åº·åº¦
echo "2. æ£€æŸ¥ API å¥åº·åº¦..."
curl -f http://localhost:8788/health || echo "API ä¸å¥åº·"

# æ£€æŸ¥ Redis è¿æ¥
echo "3. æ£€æŸ¥ Redis è¿æ¥..."
docker-compose exec redis redis-cli ping || echo "Redis è¿æ¥å¤±è´¥"

# æ£€æŸ¥ GPU çŠ¶æ€
echo "4. æ£€æŸ¥ GPU çŠ¶æ€..."
nvidia-smi --query-gpu=utilization.gpu,name --format=csv,noheader,nounits

# æ£€æŸ¥ç£ç›˜ç©ºé—´
echo "5. æ£€æŸ¥ç£ç›˜ç©ºé—´..."
df -h | grep -E "Filesystem|/dev/sda"
```

---

## è”ç³»æ”¯æŒ

### æ”¯æŒæ¸ é“

- **æŠ€æœ¯æ”¯æŒ**: support@yivideo.com
- **ç´§æ€¥è”ç³»**: +86-xxx-xxxx-xxxx
- **GitHub Issues**: https://github.com/yivideo/issues
- **æ–‡æ¡£ä¸­å¿ƒ**: https://docs.yivideo.com

### æŠ¥å‘Šé—®é¢˜æ—¶è¯·æä¾›

1. **ç³»ç»Ÿä¿¡æ¯**:
   ```bash
   uname -a
   docker --version
   docker-compose --version
   nvidia-smi
   ```

2. **æ—¥å¿—æ–‡ä»¶**:
   ```bash
   docker-compose logs > logs.txt
   ```

3. **é…ç½®æ–‡ä»¶**:
   ```bash
   cat config.yml
   ```

4. **é”™è¯¯æè¿°**:
   - é—®é¢˜æè¿°
   - å¤ç°æ­¥éª¤
   - æœŸæœ›ç»“æœ
   - å®é™…ç»“æœ

### å¸¸è§é—®é¢˜è§£ç­”

**Q: å¦‚ä½•æé«˜å¤„ç†é€Ÿåº¦ï¼Ÿ**
A: è°ƒæ•´æ‰¹å¤„ç†å¤§å°ï¼Œå¯ç”¨ Faster-Whisperï¼Œä¼˜åŒ– GPU é…ç½®ã€‚

**Q: å¦‚ä½•å¤„ç† GPU å†…å­˜ä¸è¶³ï¼Ÿ**
A: å‡å°æ‰¹å¤„ç†å¤§å°ï¼Œä½¿ç”¨åŠç²¾åº¦ï¼Œæ¸…ç†æ˜¾å­˜ç¼“å­˜ã€‚

**Q: å¦‚ä½•ç›‘æ§ç³»ç»Ÿæ€§èƒ½ï¼Ÿ**
A: ä½¿ç”¨ Prometheus + Grafanaï¼ŒæŸ¥çœ‹æ€§èƒ½ä»ªè¡¨æ¿ã€‚

**Q: å¦‚ä½•å¤‡ä»½ç³»ç»Ÿæ•°æ®ï¼Ÿ**
A: å®šæœŸå¤‡ä»½é…ç½®æ–‡ä»¶å’Œ Redis æ•°æ®ã€‚

---

## ASR ä¸è¯´è¯äººåˆ†ç¦»æœåŠ¡ Docker æ„å»ºæœ€ä½³å®è·µ

### ğŸ”§ æ„å»ºå‰æ£€æŸ¥

#### 1. ç¯å¢ƒéªŒè¯
```bash
# æ£€æŸ¥åŸºç¡€é•œåƒ
docker pull ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.1.1-gpu-cuda11.8-cudnn8.9

# éªŒè¯ç½‘ç»œè¿æ¥
curl -I https://huggingface.co
curl -I https://pypi.org/simple/faster-whisper
curl -I https://pypi.org/simple/pyannote-audio

# æ£€æŸ¥ç£ç›˜ç©ºé—´
df -h /var/lib/docker
```

#### 2. ä¾èµ–ç‰ˆæœ¬ç¡®è®¤
```bash
# æ£€æŸ¥æœåŠ¡ä¾èµ–ç‰ˆæœ¬
pip show faster-whisper
pip show pyannote.audio

# ç¡®è®¤å…¼å®¹çš„ä¾èµ–ç‰ˆæœ¬
pip show faster-whisper ctranslate2
```

### ğŸ—ï¸ æ„å»ºè¿‡ç¨‹ä¼˜åŒ–

#### 1. åˆ†å±‚æ„å»ºç­–ç•¥
```dockerfile
# åŸºç¡€ç³»ç»Ÿå±‚
FROM ccr-2vdh3abv-pub.cnc.bj.baidubce.com/paddlepaddle/paddle:3.1.1-gpu-cuda11.8-cudnn8.9

# ç³»ç»Ÿä¾èµ–å±‚ (å˜åŒ–é¢‘ç‡ä½)
RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg libsox-dev libsndfile1-dev curl wget git && \
    rm -rf /var/lib/apt/lists/*

# Python ä¾èµ–å±‚ (å˜åŒ–é¢‘ç‡ä¸­ç­‰)
COPY requirements.txt /tmp/
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# åº”ç”¨ä»£ç å±‚ (å˜åŒ–é¢‘ç‡é«˜)
COPY . /app/
```

#### 2. ç¼“å­˜ä¼˜åŒ–
```bash
# ä½¿ç”¨ --no-cache é‡æ–°æ„å»º
docker-compose build faster_whisper_service pyannote_audio_service --no-cache

# æˆ–è€…é€‰æ‹©æ€§æ¸…ç†ç¼“å­˜
docker builder prune -f
```

### ğŸ› å¸¸è§æ„å»ºé—®é¢˜è§£å†³


#### 2. ç½‘ç»œè¶…æ—¶
```dockerfile
# è®¾ç½®å›½å†…é•œåƒæº
RUN pip install --no-cache-dir -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com \
    faster-whisper pyannote.audio

# å¢åŠ è¶…æ—¶æ—¶é—´
RUN pip install --timeout 300 --retries 3 faster-whisper pyannote.audio
```

#### 3. æƒé™é—®é¢˜
```dockerfile
# ç¡®ä¿æ­£ç¡®çš„ç”¨æˆ·æƒé™
RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app && \
    chmod -R 755 /app/.cache
```

### âœ… æ„å»ºéªŒè¯æ¸…å•

#### 1. åŠŸèƒ½éªŒè¯
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
docker-compose ps faster_whisper_service pyannote_audio_service

# éªŒè¯ Celery Worker
docker exec faster_whisper_service celery -A app.celery_app inspect active
docker exec pyannote_audio_service celery -A app.celery_app inspect active

# æµ‹è¯•æ¨¡å‹åŠ è½½
docker exec faster_whisper_service python -c "from faster_whisper import WhisperModel; print('Import successful')"
docker exec pyannote_audio_service python -c "from pyannote.audio import Pipeline; print('Import successful')"
```

#### 2. é…ç½®éªŒè¯
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
docker exec faster_whisper_service env | grep "TRANSFORMERS"
docker exec pyannote_audio_service env | grep "HF_"

# æ£€æŸ¥ç¼“å­˜ç›®å½• (è·¯å¾„å–å†³äº config.yml)
# docker exec <service_name> ls -la /path/to/your/model/cache/
```

#### 3. æ€§èƒ½éªŒè¯
```bash
# è¿è¡Œç®€å•æµ‹è¯• (ç¤ºä¾‹)
# (å¯è°ƒç”¨ API å‘èµ·ä¸€ä¸ªå°å‹æµ‹è¯•å·¥ä½œæµ)

# æ£€æŸ¥æ—¥å¿—
docker-compose logs --tail=50 faster_whisper_service

# ç›‘æ§èµ„æºä½¿ç”¨
docker stats faster_whisper_service
```

### ğŸš€ ç”Ÿäº§éƒ¨ç½²å»ºè®®

#### 1. é•œåƒç®¡ç†
```bash
# æ ‡è®°ç”Ÿäº§é•œåƒ
docker tag yivideo-faster_whisper_service:latest yivideo-faster_whisper_service:v2.0.1
docker tag yivideo-pyannote_audio_service:latest yivideo-pyannote_audio_service:v2.0.1

# æ¨é€åˆ°ç§æœ‰ä»“åº“
docker push registry.example.com/yivideo-faster_whisper_service:v2.0.1
docker push registry.example.com/yivideo-pyannote_audio_service:v2.0.1
```

#### 2. å¥åº·æ£€æŸ¥
```dockerfile
# åœ¨ Dockerfile ä¸­æ·»åŠ å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD celery -A app.tasks.celery_app inspect active || exit 1
```

#### 3. æ—¥å¿—ç®¡ç†
```yaml
# åœ¨ docker-compose.yml ä¸­é…ç½®æ—¥å¿—
logging:
  driver: "json-file"
  options:
    max-size: "100m"
    max-file: "5"
```

### ğŸ“Š æ€§èƒ½è°ƒä¼˜

#### 1. èµ„æºé™åˆ¶
```yaml
# docker-compose.yml ä¸­çš„èµ„æºé…ç½®
deploy:
  resources:
    limits:
      memory: 8G
      cpus: '4'
    reservations:
      memory: 4G
      cpus: '2'
```

#### 2. å­˜å‚¨ä¼˜åŒ–
```yaml
# ä½¿ç”¨ tmpfs æå‡ä¸´æ—¶æ–‡ä»¶æ€§èƒ½
tmpfs:
  - /tmp
```

#### 3. ç½‘ç»œä¼˜åŒ–
```yaml
# ä½¿ç”¨ä¸“ç”¨ç½‘ç»œ
networks:
  asr_net:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

---

## æ€»ç»“

æœ¬æ•…éšœæ’é™¤æŒ‡å—æä¾›äº† YiVideo ç³»ç»Ÿå¸¸è§é—®é¢˜çš„è¯Šæ–­å’Œè§£å†³æ–¹æ¡ˆï¼Œä»¥åŠDockeræ„å»ºçš„æœ€ä½³å®è·µã€‚è¯·æŒ‰ç…§æœ¬æŒ‡å—çš„æ­¥éª¤è¿›è¡Œæ•…éšœæ’é™¤ï¼Œå¦‚ä»æ— æ³•è§£å†³é—®é¢˜ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒã€‚

å®šæœŸè¿›è¡Œç³»ç»Ÿç»´æŠ¤å’Œæ€§èƒ½ç›‘æ§ï¼Œå¯ä»¥æœ‰æ•ˆé¢„é˜²é—®é¢˜çš„å‘ç”Ÿã€‚

---


---

*æœ€åæ›´æ–°: 2025-11-09 | æ–‡æ¡£ç‰ˆæœ¬: 1.1*