# services/workers/paddleocr_service/app/modules/base_detector.py
# -*- coding: utf-8 -*-

"""
åŸºç¡€æ£€æµ‹å™¨ç±»

ä¸ºæ‰€æœ‰æ£€æµ‹å™¨æä¾›é€šç”¨åŠŸèƒ½å’Œæ¥å£ï¼Œå‡å°‘ä»£ç é‡å¤ï¼Œæé«˜å¯ç»´æŠ¤æ€§ã€‚

æ ¹æ® DETECTOR_ARCHITECTURE_ANALYSIS_REPORT.md çš„é‡æ„å»ºè®®å®ç°
"""

import gc
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Tuple, Optional
import numpy as np
import torch

from services.common.logger import get_logger

logger = get_logger('base_detector')


class BaseDetector(ABC):
    """
    åŸºç¡€æ£€æµ‹å™¨æŠ½è±¡ç±»

    æä¾›æ‰€æœ‰æ£€æµ‹å™¨çš„é€šç”¨åŠŸèƒ½ï¼š
    - ç»Ÿä¸€çš„åˆå§‹åŒ–å’Œé…ç½®ç®¡ç†
    - GPUèµ„æºç®¡ç†
    - å†…å­˜ä¼˜åŒ–
    - è¿›åº¦æ˜¾ç¤º
    - é”™è¯¯å¤„ç†
    """

    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–åŸºç¡€æ£€æµ‹å™¨

        Args:
            config: æ£€æµ‹å™¨é…ç½®å­—å…¸
        """
        self.config = config
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

        # é€šç”¨é…ç½®éªŒè¯å’Œè®¾ç½®
        self._validate_common_config()

        # GPUå†…å­˜ç®¡ç†é…ç½®
        self.frame_memory_estimate_mb = config.get('frame_memory_estimate_mb', 0.307)
        self.progress_interval_frames = config.get('progress_interval_frames', 1000)
        self.progress_interval_batches = config.get('progress_interval_batches', 50)

        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'frames_processed': 0,
            'batches_processed': 0,
            'gpu_memory_errors': 0,
            'start_time': None
        }

        logger.info(f"{self.__class__.__name__} åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")

    def _validate_common_config(self):
        """éªŒè¯é€šç”¨é…ç½®å‚æ•°"""
        # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
        required_configs = []
        for config_key in required_configs:
            if config_key not in self.config:
                raise ValueError(f"ç¼ºå°‘å¿…è¦é…ç½®é¡¹: {config_key}")

    def _log_progress(self, current: int, total: int, stage: str = "å¤„ç†"):
        """
        è®°å½•è¿›åº¦ä¿¡æ¯

        Args:
            current: å½“å‰è¿›åº¦
            total: æ€»æ•°
            stage: å¤„ç†é˜¶æ®µæè¿°
        """
        if current % self.progress_interval_frames == 0:
            progress = (current / total) * 100
            logger.info(f"ğŸ“Š {stage}è¿›åº¦: {current}/{total} ({progress:.1f}%)")

    def _log_batch_progress(self, batch_count: int, frame_count: int, additional_info: str = ""):
        """
        è®°å½•æ‰¹æ¬¡å¤„ç†è¿›åº¦

        Args:
            batch_count: æ‰¹æ¬¡æ•°é‡
            frame_count: å¸§æ•°é‡
            additional_info: é™„åŠ ä¿¡æ¯
        """
        if batch_count % self.progress_interval_batches == 0:
            info = f"æ‰¹æ¬¡: {batch_count}, å¸§: {frame_count}"
            if additional_info:
                info += f", {additional_info}"
            logger.info(f"  ğŸ“Š å·²å¤„ç† {info}")

    def _optimize_gpu_memory(self):
        """ä¼˜åŒ–GPUå†…å­˜ä½¿ç”¨"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

    def _safe_gpu_operation(self, operation_func, *args, **kwargs):
        """
        å®‰å…¨æ‰§è¡ŒGPUæ“ä½œï¼Œå¤„ç†å†…å­˜ä¸è¶³å¼‚å¸¸

        Args:
            operation_func: è¦æ‰§è¡Œçš„æ“ä½œå‡½æ•°
            *args, **kwargs: æ“ä½œå‡½æ•°çš„å‚æ•°

        Returns:
            æ“ä½œç»“æœæˆ–Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        try:
            return operation_func(*args, **kwargs)
        except RuntimeError as e:
            if "out of memory" in str(e).lower():
                self.stats['gpu_memory_errors'] += 1
                logger.warning(f"âš ï¸ GPUå†…å­˜ä¸è¶³ï¼Œè·³è¿‡æ“ä½œ: {e}")
                self._optimize_gpu_memory()
                return None
            else:
                raise e

    def _estimate_memory_usage(self, frame_count: int) -> float:
        """
        ä¼°ç®—å†…å­˜ä½¿ç”¨é‡

        Args:
            frame_count: å¸§æ•°é‡

        Returns:
            ä¼°ç®—çš„å†…å­˜ä½¿ç”¨é‡(MB)
        """
        return frame_count * self.frame_memory_estimate_mb

    def _start_processing(self):
        """å¼€å§‹å¤„ç†å‰çš„å‡†å¤‡å·¥ä½œ"""
        import time
        self.stats['start_time'] = time.time()
        logger.info(f"ğŸš€ å¼€å§‹ {self.__class__.__name__} å¤„ç†")

    def _finish_processing(self):
        """å®Œæˆå¤„ç†åçš„æ¸…ç†å·¥ä½œ"""
        import time
        if self.stats['start_time']:
            duration = time.time() - self.stats['start_time']
            logger.info(f"âœ… {self.__class__.__name__} å¤„ç†å®Œæˆ")
            logger.info(f"â±ï¸  å¤„ç†æ—¶é—´: {duration:.2f}ç§’")
            logger.info(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: å¸§={self.stats['frames_processed']}, "
                       f"æ‰¹æ¬¡={self.stats['batches_processed']}, "
                       f"GPUé”™è¯¯={self.stats['gpu_memory_errors']}")

        # æœ€ç»ˆå†…å­˜ä¼˜åŒ–
        self._optimize_gpu_memory()

    @abstractmethod
    def detect(self, video_path: str, *args, **kwargs) -> Any:
        """
        æŠ½è±¡æ£€æµ‹æ–¹æ³•

        æ‰€æœ‰å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            *args, **kwargs: å…¶ä»–å‚æ•°

        Returns:
            æ£€æµ‹ç»“æœ
        """
        pass

    @abstractmethod
    def get_detector_name(self) -> str:
        """
        è·å–æ£€æµ‹å™¨åç§°

        Returns:
            æ£€æµ‹å™¨åç§°
        """
        pass

    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return self.stats.copy()

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'frames_processed': 0,
            'batches_processed': 0,
            'gpu_memory_errors': 0,
            'start_time': None
        }


class GPUDecorator:
    """
    GPUæ“ä½œè£…é¥°å™¨ï¼Œä¸ºæ£€æµ‹å™¨æä¾›GPUå†…å­˜ä¿æŠ¤
    """

    def __init__(self, detector_instance):
        self.detector = detector_instance

    def __call__(self, func):
        def wrapper(*args, **kwargs):
            return self.detector._safe_gpu_operation(func, *args, **kwargs)
        return wrapper


class ConfigManager:
    """
    é…ç½®ç®¡ç†å™¨ï¼Œæä¾›ç»Ÿä¸€çš„é…ç½®éªŒè¯å’Œç®¡ç†åŠŸèƒ½
    """

    @staticmethod
    def validate_config(config: Dict[str, Any], required_keys: List[str],
                       optional_keys: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        éªŒè¯å’Œè§„èŒƒåŒ–é…ç½®

        Args:
            config: åŸå§‹é…ç½®
            required_keys: å¿…éœ€çš„é…ç½®é”®
            optional_keys: å¯é€‰é…ç½®é”®åŠå…¶é»˜è®¤å€¼

        Returns:
            éªŒè¯åçš„é…ç½®
        """
        validated_config = config.copy()

        # æ£€æŸ¥å¿…éœ€é”®
        for key in required_keys:
            if key not in validated_config:
                raise ValueError(f"ç¼ºå°‘å¿…éœ€é…ç½®é¡¹: {key}")

        # è®¾ç½®å¯é€‰é”®çš„é»˜è®¤å€¼
        if optional_keys:
            for key, default_value in optional_keys.items():
                validated_config.setdefault(key, default_value)

        return validated_config

    @staticmethod
    def validate_range(value: Any, min_val: Any, max_val: Any, name: str) -> Any:
        """
        éªŒè¯æ•°å€¼èŒƒå›´

        Args:
            value: è¦éªŒè¯çš„å€¼
            min_val: æœ€å°å€¼
            max_val: æœ€å¤§å€¼
            name: å‚æ•°åç§°

        Returns:
            éªŒè¯åçš„å€¼
        """
        if not (min_val <= value <= max_val):
            raise ValueError(f"{name}å¿…é¡»åœ¨{min_val}å’Œ{max_val}ä¹‹é—´ï¼Œå½“å‰å€¼: {value}")
        return value


class ProgressTracker:
    """
    è¿›åº¦è·Ÿè¸ªå™¨ï¼Œæä¾›ç»Ÿä¸€çš„è¿›åº¦æ˜¾ç¤ºåŠŸèƒ½
    """

    def __init__(self, total_items: int, name: str = "å¤„ç†"):
        self.total_items = total_items
        self.name = name
        self.processed_items = 0
        self.start_time = None

    def start(self):
        """å¼€å§‹è·Ÿè¸ª"""
        import time
        self.start_time = time.time()
        logger.info(f"ğŸš€ å¼€å§‹ {self.name}")

    def update(self, increment: int = 1, additional_info: str = ""):
        """
        æ›´æ–°è¿›åº¦

        Args:
            increment: å¢é‡
            additional_info: é™„åŠ ä¿¡æ¯
        """
        self.processed_items += increment

        if self.processed_items % 1000 == 0:  # æ¯1000é¡¹æ˜¾ç¤ºä¸€æ¬¡
            progress = (self.processed_items / self.total_items) * 100
            info = f"è¿›åº¦: {self.processed_items}/{self.total_items} ({progress:.1f}%)"
            if additional_info:
                info += f" - {additional_info}"
            logger.info(f"ğŸ“Š {self.name} {info}")

    def finish(self):
        """å®Œæˆè·Ÿè¸ª"""
        import time
        if self.start_time:
            duration = time.time() - self.start_time
            logger.info(f"âœ… {self.name} å®Œæˆ - è€—æ—¶: {duration:.2f}ç§’")