# pipeline/modules/ocr.py

import torch
import numpy as np
import multiprocessing
import os
import time
import yaml
import cv2
from paddleocr import PaddleOCR
from typing import List, Tuple, Dict, Any

from .decoder import GPUDecoder
from .change_detector import ChangeType
from ..utils.progress_logger import create_stage_progress

# å…¨å±€å˜é‡ï¼Œç”¨äºå¤šè¿›ç¨‹workeråˆå§‹åŒ–
ocr_engine_process_global = None
# å…¨å±€è°ƒè¯•è®¡æ•°å™¨
debug_frame_counter = 0

class MultiProcessOCREngine:
    """
    [V3] Event-driven multiprocess OCR engine.
    ä½¿ç”¨å¤šè¿›ç¨‹å¹¶å‘æ¨¡å¼è¯†åˆ«æ–‡æœ¬ï¼Œåœ¨frames marked as needing OCR (APPEARED, CONTENT_CHANGED)
    å¹¶ä¼ é€’æ‰€æœ‰event typesç»™åå¤„ç†å™¨ã€‚
    åŸºäºsimple_test.pyéªŒè¯çš„å¤šè¿›ç¨‹å¹¶å‘å®ç°ã€‚
    """
    def __init__(self, config):
        self.config = config
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.lang = config.get('lang', 'en')
        
        # å¤šè¿›ç¨‹ç›¸å…³é…ç½®
        self.num_workers = self._get_num_workers_from_config()
        print(f"æ¨¡å—: OCRå¼•æ“å·²åŠ è½½ (V3 - å¤šè¿›ç¨‹å¹¶å‘), ä½¿ç”¨è¯­è¨€: {self.lang}, å·¥ä½œè¿›ç¨‹æ•°: {self.num_workers}")

    def _get_num_workers_from_config(self):
        """ä»é…ç½®ä¸­è·å–å·¥ä½œè¿›ç¨‹æ•°é‡ï¼Œå¦‚æœæœªé…ç½®åˆ™ä½¿ç”¨é»˜è®¤å€¼2"""
        # é¦–å…ˆå°è¯•ä»ocré…ç½®æ®µè·å–num_workers
        try:
            num_workers = self.config.get('num_workers')
            if isinstance(num_workers, int) and num_workers > 0:
                print(f"ä»OCRé…ç½®åŠ è½½ï¼šnum_workers = {num_workers}")
                return num_workers
        except Exception:
            pass
            
        # å¦‚æœOCRé…ç½®æ®µæ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨é€šç”¨é…ç½®åŠ è½½å™¨ï¼ˆå‘åå…¼å®¹ï¼‰
        try:
            # å¯¼å…¥é€šç”¨é…ç½®åŠ è½½å™¨
            import sys
            sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
            from utils.config_loader import get_num_workers
            num_workers = get_num_workers(section='area_detector', default_workers=2)
            print(f"ä»é€šç”¨é…ç½®åŠ è½½å™¨åŠ è½½ï¼šnum_workers = {num_workers}")
            return num_workers
        except Exception as e:
            print(f"é€šç”¨é…ç½®åŠ è½½å™¨åŠ è½½å¤±è´¥: {e}")
        
        print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°æœ‰æ•ˆçš„num_workersé…ç½®ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼2ã€‚")
        return 2

    def recognize(self, video_path: str, decoder: GPUDecoder, change_events: List[Tuple[int, ChangeType]], subtitle_area: Tuple[int, int, int, int], total_frames: int = 0) -> Dict[int, Tuple[str, Any, ChangeType]]:
        """
        ä½¿ç”¨å¤šè¿›ç¨‹å¹¶å‘æ¨¡å¼å¯¹å¿…è¦çš„framesè¿›è¡ŒOCRå¤„ç†ã€‚
        """
        frames_to_ocr_indices = [
            frame_idx for frame_idx, event_type in change_events 
            if event_type in [ChangeType.TEXT_APPEARED, ChangeType.CONTENT_CHANGED]
        ]

        if not frames_to_ocr_indices:
            print("æ²¡æœ‰éœ€è¦OCRçš„å…³é”®äº‹ä»¶ã€‚")
            # Still need to return disappearance events
            return {frame_idx: (None, None, event_type) for frame_idx, event_type in change_events}

        print(f"æ£€æµ‹åˆ° {len(change_events)} ä¸ªå…³é”®äº‹ä»¶, å…¶ä¸­ {len(frames_to_ocr_indices)} ä¸ªéœ€è¦è¿›è¡ŒOCR")
        x1, y1, x2, y2 = subtitle_area

        # 1. Decode and extract only the frames that need OCR
        key_frames_map = self._extract_key_frames(video_path, decoder, frames_to_ocr_indices, (x1, y1, x2, y2))
        if not key_frames_map:
            return {}

        # 2. ä½¿ç”¨å¤šè¿›ç¨‹å¹¶å‘å¤„ç†OCR
        ocr_results_map = self._multiprocess_ocr_batch(key_frames_map, subtitle_area, total_frames)

        # 3. Construct final event-aware dictionary
        final_results = {}
        for frame_idx, event_type in change_events:
            if frame_idx in ocr_results_map:
                text, bbox = ocr_results_map[frame_idx]
                final_results[frame_idx] = (text, bbox, event_type)
            elif event_type == ChangeType.TEXT_DISAPPEARED:
                final_results[frame_idx] = (None, None, event_type)

        print("âœ… OCRè¯†åˆ«å®Œæˆ")
        return final_results

    def _multiprocess_ocr_batch(self, key_frames_map: Dict[int, np.ndarray], subtitle_area: Tuple[int, int, int, int], total_frames: int) -> Dict[int, Tuple[str, Any]]:
        """
        ä½¿ç”¨å¤šè¿›ç¨‹å¹¶å‘å¤„ç†OCRè¯†åˆ«ã€‚
        å‚è€ƒsimple_test.pyä¸­çš„test_multiprocess_concurrentå®ç°ã€‚
        """
        # æ„é€ workerä»»åŠ¡åˆ—è¡¨ï¼š(frame_idx, image_data)
        worker_tasks = [(frame_idx, image_data) for frame_idx, image_data in key_frames_map.items()]
        
        # åˆ›å»ºOCRå¤„ç†è¿›åº¦æ¡
        progress_bar = create_stage_progress("OCRæ–‡æœ¬è¯†åˆ«", len(worker_tasks), 
                                           show_rate=True, show_eta=True)
        
        ocr_results_map = {}
        pool = None
        
        # å…ˆå°è¯•ä½¿ç”¨ProcessPoolExecutorå®ç°å®æ—¶è¿›åº¦æ›´æ–°
        success_count = 0
        error_count = 0
        x1, y1, x2, y2 = subtitle_area
        
        try:
            from concurrent.futures import ProcessPoolExecutor, as_completed
            
            # åˆ›å»ºè¿›ç¨‹æ± æ‰§è¡Œå™¨
            with ProcessPoolExecutor(
                max_workers=self.num_workers,
                initializer=_worker_initializer,
                initargs=(self.lang,)
            ) as executor:
                
                start_time = time.time()
                
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_task = {}
                for task in worker_tasks:
                    future = executor.submit(_ocr_worker_task, task)
                    future_to_task[future] = task
                
                # å®æ—¶æ”¶é›†ç»“æœå¹¶æ›´æ–°è¿›åº¦æ¡
                for future in as_completed(future_to_task, timeout=600):  # 10åˆ†é’Ÿæ€»è¶…æ—¶
                    try:
                        result = future.result(timeout=60)  # å•ä¸ªä»»åŠ¡60ç§’è¶…æ—¶
                        
                        if result:  # è¿‡æ»¤æ‰Noneç»“æœ
                            frame_idx, texts, boxes = result
                            if texts and boxes:
                                # ç¡®ä¿textsæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
                                if isinstance(texts, list) and len(texts) > 0:
                                    full_text = " ".join(str(text) for text in texts if text)
                                    
                                    # å®‰å…¨åœ°å¤„ç†boxesæ•°æ®
                                    try:
                                        if boxes and len(boxes) > 0:
                                            # ç¡®ä¿boxesæ˜¯æ•°å€¼ç±»å‹çš„numpyæ•°ç»„
                                            valid_boxes = []
                                            for box in boxes:
                                                if isinstance(box, (list, np.ndarray)):
                                                    # è½¬æ¢ä¸ºfloatç±»å‹çš„numpyæ•°ç»„
                                                    box_array = np.array(box, dtype=np.float32)
                                                    valid_boxes.append(box_array)
                                            
                                            if valid_boxes:
                                                all_points = np.vstack(valid_boxes).reshape(-1, 2)
                                                min_x, min_y = np.min(all_points, axis=0)
                                                max_x, max_y = np.max(all_points, axis=0)
                                                
                                                abs_bbox = (int(min_x), int(min_y + y1), int(max_x), int(max_y + y1))
                                                ocr_results_map[frame_idx] = (full_text.strip(), abs_bbox)
                                                success_count += 1
                                            else:
                                                error_count += 1
                                        else:
                                            error_count += 1
                                    except Exception as box_error:
                                        error_count += 1
                                else:
                                    error_count += 1
                        else:
                            error_count += 1
                        
                        # å®æ—¶æ›´æ–°è¿›åº¦æ¡
                        progress_bar.update(1, æˆåŠŸ=success_count, å¤±è´¥=error_count)
                        
                    except Exception as e:
                        task = future_to_task[future]
                        frame_idx = task[0]
                        print(f"ä»»åŠ¡ {frame_idx} å¤„ç†å¤±è´¥: {e}")
                        error_count += 1
                        progress_bar.update(1, æˆåŠŸ=success_count, å¤±è´¥=error_count)
                
                end_time = time.time()
                ocr_duration = end_time - start_time
                progress_bar.finish(f"âœ… OCRè¯†åˆ«å®Œæˆ: {len(worker_tasks)}é¡¹ï¼Œè€—æ—¶: {ocr_duration/60:.1f}m, å¹³å‡é€Ÿç‡: {len(worker_tasks)/ocr_duration:.1f}/s")
            
        except Exception as e:
            print(f"ProcessPoolExecutoræ‰§è¡Œå¤±è´¥ï¼Œå›é€€åˆ°Pool.imapæ–¹å¼: {e}")
            
            # å›é€€åˆ°ä½¿ç”¨multiprocessing.Poolçš„imapæ–¹å¼å®ç°å®æ—¶è¿›åº¦
            try:
                pool = multiprocessing.Pool(
                    processes=self.num_workers, 
                    initializer=_worker_initializer,
                    initargs=(self.lang,)
                )
                
                start_time = time.time()
                
                # ä½¿ç”¨imapè€Œémapæ¥è·å¾—å®æ—¶ç»“æœ
                results_iter = pool.imap(_ocr_worker_task, worker_tasks)
                
                success_count = 0
                error_count = 0
                
                for i, result in enumerate(results_iter):
                    if result:  # è¿‡æ»¤æ‰Noneç»“æœ
                        frame_idx, texts, boxes = result
                        if texts and boxes:
                            # ç¡®ä¿textsæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
                            if isinstance(texts, list) and len(texts) > 0:
                                full_text = " ".join(str(text) for text in texts if text)
                                
                                # å®‰å…¨åœ°å¤„ç†boxesæ•°æ®
                                try:
                                    if boxes and len(boxes) > 0:
                                        # ç¡®ä¿boxesæ˜¯æ•°å€¼ç±»å‹çš„numpyæ•°ç»„
                                        valid_boxes = []
                                        for box in boxes:
                                            if isinstance(box, (list, np.ndarray)):
                                                # è½¬æ¢ä¸ºfloatç±»å‹çš„numpyæ•°ç»„
                                                box_array = np.array(box, dtype=np.float32)
                                                valid_boxes.append(box_array)
                                        
                                        if valid_boxes:
                                            all_points = np.vstack(valid_boxes).reshape(-1, 2)
                                            min_x, min_y = np.min(all_points, axis=0)
                                            max_x, max_y = np.max(all_points, axis=0)
                                            
                                            abs_bbox = (int(min_x), int(min_y + y1), int(max_x), int(max_y + y1))
                                            ocr_results_map[frame_idx] = (full_text.strip(), abs_bbox)
                                            success_count += 1
                                        else:
                                            error_count += 1
                                    else:
                                        error_count += 1
                                except Exception as box_error:
                                    error_count += 1
                            else:
                                error_count += 1
                    else:
                        error_count += 1
                    
                    # å®æ—¶æ›´æ–°è¿›åº¦æ¡
                    progress_bar.update(1, æˆåŠŸ=success_count, å¤±è´¥=error_count)
                
                end_time = time.time()
                ocr_duration = end_time - start_time
                progress_bar.finish(f"âœ… OCRè¯†åˆ«å®Œæˆ: {len(worker_tasks)}é¡¹ï¼Œè€—æ—¶: {ocr_duration/60:.1f}m, å¹³å‡é€Ÿç‡: {len(worker_tasks)/ocr_duration:.1f}/s")
                
            except Exception as e2:
                progress_bar.finish(f"âŒ å¤šè¿›ç¨‹OCRå¤„ç†å¤±è´¥: {e2}")
                import traceback
                traceback.print_exc()
            finally:
                if pool:
                    try:
                        pool.close()
                        pool.join()
                    except:
                        pass
        
        return ocr_results_map

    def _extract_key_frames(self, video_path: str, decoder: GPUDecoder, key_frame_indices: List[int], crop_rect: Tuple[int, int, int, int]) -> Dict[int, np.ndarray]:
        """Efficiently decodes and crops only the key frames."""
        key_frames_to_get = set(key_frame_indices)
        key_frames_map = {}
        x1, y1, x2, y2 = crop_rect
        
        # åˆ›å»ºè°ƒè¯•ç›®å½• - å·²æ³¨é‡Šï¼Œé¿å…ç£ç›˜ç©ºé—´å ç”¨
        # debug_dir = "./pics"
        # os.makedirs(debug_dir, exist_ok=True)
        
        # è®¡æ•°å™¨ï¼Œåªä¿å­˜å‰10å¸§ - å·²æ³¨é‡Š
        # saved_count = 0
        # MAX_DEBUG_FRAMES = 10
        
        current_frame_idx = 0
        for batch_tensor, _ in decoder.decode(video_path):
            for frame_tensor in batch_tensor:
                if current_frame_idx in key_frames_to_get:
                    # æ­£ç¡®çš„tensoråˆ‡ç‰‡ - å·²ä¿®å¤ç»´åº¦é—®é¢˜
                    cropped_tensor = frame_tensor[:, y1:y2, x1:x2]
                    frame_np = cropped_tensor.permute(1, 2, 0).cpu().numpy().astype(np.uint8)
                    key_frames_map[current_frame_idx] = frame_np
                    
                    # ä¿å­˜å‰10å¸§è°ƒè¯•å›¾åƒï¼ˆé˜¶æ®µ1ï¼šè£å‰ªåçš„å›¾åƒï¼‰ - å·²æ³¨é‡Š
                    # if saved_count < MAX_DEBUG_FRAMES:
                    #     debug_path = os.path.join(debug_dir, f"stage1_cropped_frame_{current_frame_idx:06d}.jpg")
                    #     cv2.imwrite(debug_path, cv2.cvtColor(frame_np, cv2.COLOR_RGB2BGR))
                    #     saved_count += 1
                    
                    key_frames_to_get.remove(current_frame_idx)
                
                current_frame_idx += 1
            
            if not key_frames_to_get:
                break
        
        return key_frames_map

    def recognize_keyframes(self, video_path: str, decoder: GPUDecoder, keyframes: List[int], 
                           subtitle_area: Tuple[int, int, int, int], total_frames: int = 0) -> Dict[int, Tuple[str, Any]]:
        """
        å…³é”®å¸§é©±åŠ¨çš„OCRè¯†åˆ«æ–¹æ³• - é€‚é…æ–°æ¶æ„
        
        åŸºäºKeyFrameDetectoræä¾›çš„å…³é”®å¸§åˆ—è¡¨è¿›è¡ŒOCRè¯†åˆ«ï¼Œ
        æ›¿ä»£åŸæœ‰çš„äº‹ä»¶é©±åŠ¨æ¨¡å¼ã€‚
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            decoder: GPUè§£ç å™¨å®ä¾‹
            keyframes: å…³é”®å¸§ç´¢å¼•åˆ—è¡¨ [0, 45, 89, ...]
            subtitle_area: å­—å¹•åŒºåŸŸåæ ‡ (x1, y1, x2, y2)
            total_frames: è§†é¢‘æ€»å¸§æ•°ï¼ˆç”¨äºè¿›åº¦æ˜¾ç¤ºï¼‰
            
        Returns:
            Dict[int, Tuple[str, bbox]]: å…³é”®å¸§OCRç»“æœæ˜ å°„
            {
                0: ("Hello World", (x1, y1, x2, y2)),
                45: ("Nice to meet you", (x1, y1, x2, y2)),
                ...
            }
        """
        if not keyframes:
            print("âš ï¸ æœªæä¾›å…³é”®å¸§åˆ—è¡¨ï¼ŒOCRè¯†åˆ«è·³è¿‡")
            return {}
            
        print(f"ğŸ” å¼€å§‹å…³é”®å¸§OCRè¯†åˆ«: {len(keyframes)} ä¸ªå…³é”®å¸§")
        x1, y1, x2, y2 = subtitle_area
        
        # 1. æå–å…³é”®å¸§å›¾åƒæ•°æ®
        key_frames_map = self._extract_key_frames(video_path, decoder, keyframes, (x1, y1, x2, y2))
        if not key_frames_map:
            print("âŒ å…³é”®å¸§æå–å¤±è´¥")
            return {}
            
        # 2. ä½¿ç”¨å¤šè¿›ç¨‹å¹¶å‘è¿›è¡ŒOCRè¯†åˆ«
        ocr_results_map = self._multiprocess_ocr_batch(key_frames_map, subtitle_area, total_frames)
        
        print(f"âœ… å…³é”®å¸§OCRè¯†åˆ«å®Œæˆ: {len(ocr_results_map)} ä¸ªç»“æœ")
        return ocr_results_map

    def recognize_keyframes_from_cache(self, keyframe_cache: Dict[int, np.ndarray], 
                                      subtitle_area: Tuple[int, int, int, int], 
                                      total_frames: int = 0) -> Dict[int, Tuple[str, Any]]:
        """
        ğŸ†• ä¼˜åŒ–æ–¹æ³•ï¼šç›´æ¥ä»ç¼“å­˜çš„å…³é”®å¸§å›¾åƒè¿›è¡ŒOCRè¯†åˆ«
        
        é¿å…é‡å¤è§†é¢‘è§£ç ï¼Œç›´æ¥ä½¿ç”¨å…³é”®å¸§æ£€æµ‹é˜¶æ®µç¼“å­˜çš„å›¾åƒæ•°æ®è¿›è¡ŒOCRå¤„ç†ã€‚
        è¿™æ˜¯æ ¸å¿ƒæ€§èƒ½ä¼˜åŒ–ï¼šæ¶ˆé™¤ç¬¬äºŒæ¬¡è§†é¢‘è§£ç çš„æ—¶é—´å¼€é”€ã€‚
        
        Args:
            keyframe_cache: å…³é”®å¸§å›¾åƒç¼“å­˜ {frame_idx: image_array, ...}
            subtitle_area: å­—å¹•åŒºåŸŸåæ ‡ (x1, y1, x2, y2) 
            total_frames: è§†é¢‘æ€»å¸§æ•°ï¼ˆç”¨äºè¿›åº¦æ˜¾ç¤ºï¼‰
            
        Returns:
            Dict[int, Tuple[str, bbox]]: å…³é”®å¸§OCRç»“æœæ˜ å°„
            {
                0: ("Hello World", (x1, y1, x2, y2)),
                45: ("Nice to meet you", (x1, y1, x2, y2)),
                ...
            }
        """
        if not keyframe_cache:
            print("âš ï¸ å…³é”®å¸§ç¼“å­˜ä¸ºç©ºï¼ŒOCRè¯†åˆ«è·³è¿‡")
            return {}
            
        print(f"ğŸ” å¼€å§‹å…³é”®å¸§OCRè¯†åˆ«: {len(keyframe_cache)} ä¸ªç¼“å­˜å…³é”®å¸§")
        print(f"âš¡ æ€§èƒ½ä¼˜åŒ–: è·³è¿‡è§†é¢‘è§£ç ï¼Œç›´æ¥ä½¿ç”¨ç¼“å­˜æ•°æ®")
        
        # ä½¿ç”¨å¤šè¿›ç¨‹å¹¶å‘è¿›è¡ŒOCRè¯†åˆ« (å¤ç”¨ç°æœ‰é€»è¾‘)
        ocr_results_map = self._multiprocess_ocr_batch(keyframe_cache, subtitle_area, total_frames)
        
        print(f"âœ… å…³é”®å¸§OCRè¯†åˆ«å®Œæˆ: {len(ocr_results_map)} ä¸ªç»“æœ")
        print(f"ğŸš€ æ€§èƒ½æå‡: æ¶ˆé™¤äº†ç¬¬äºŒæ¬¡è§†é¢‘è§£ç æ—¶é—´")
        return ocr_results_map


# --- å¤šè¿›ç¨‹Workerå‡½æ•°ï¼ˆæ¨¡å—çº§åˆ«å‡½æ•°ï¼Œä¾›multiprocessingè°ƒç”¨ï¼‰ ---

def _worker_initializer(lang='en'):
    """
    å¤šè¿›ç¨‹workeråˆå§‹åŒ–å‡½æ•°ã€‚
    æ¯ä¸ªå­è¿›ç¨‹ä¼šè°ƒç”¨æ­¤å‡½æ•°æ¥åˆå§‹åŒ–è‡ªå·±ç‹¬ç«‹çš„PaddleOCRå®ä¾‹ã€‚
    ä½¿ç”¨åŸºäºæµ‹è¯•ç»“æœä¼˜åŒ–çš„ç»Ÿä¸€é…ç½®ã€‚
    """
    global ocr_engine_process_global
    pid = os.getpid()
    
    # ä½¿ç”¨é€šç”¨é…ç½®åŠ è½½å™¨è·å–å®Œæ•´çš„ PaddleOCR 3.x é…ç½®
    try:
        # å¯¼å…¥é€šç”¨é…ç½®åŠ è½½å™¨
        import sys
        sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
        from utils.config_loader import get_paddleocr_config
        
        # ğŸ¯ æ ¸å¿ƒä¿®å¤ï¼šç›´æ¥è·å–å®Œæ•´çš„ä¼˜åŒ–é…ç½®
        ocr_kwargs = get_paddleocr_config()
        print(f"[PID: {pid}] ğŸ“‹ ä»é…ç½®æ–‡ä»¶åŠ è½½ PaddleOCR 3.x å®Œæ•´å‚æ•°:")
        print(f"[PID: {pid}] ğŸ¯ è¯­è¨€={ocr_kwargs['lang']}, æ¨¡å‹ç‰ˆæœ¬={ocr_kwargs['ocr_version']}")
        print(f"[PID: {pid}] ğŸ“Š å…³é”®å‚æ•°: thresh={ocr_kwargs['text_det_thresh']}, box_thresh={ocr_kwargs['text_det_box_thresh']}")
        
    except Exception as e:
        print(f"[PID: {pid}] âš ï¸  é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æµ‹è¯•éªŒè¯çš„æœ€ä½³å‚æ•°: {e}")
        # å³ä½¿é…ç½®åŠ è½½å¤±è´¥ï¼Œä¹Ÿä½¿ç”¨æµ‹è¯•éªŒè¯çš„æœ€ä½³é…ç½®
        ocr_kwargs = {
            'lang': 'en',  # ğŸ”¥ æµ‹è¯•è¯æ˜è‹±æ–‡æ¨¡å¼æ•ˆæœæœ€ä½³(99.96%ç½®ä¿¡åº¦)
            'ocr_version': 'PP-OCRv5',
            'text_det_limit_side_len': 736,
            'text_det_thresh': 0.30,
            'text_det_box_thresh': 0.60,
            'text_det_unclip_ratio': 1.50,
            'text_rec_score_thresh': 0,
            'use_doc_orientation_classify': False,
            'use_doc_unwarping': False,
            'use_textline_orientation': False
        }
    
    print(f"[PID: {pid}] ğŸš€ å¼€å§‹åˆå§‹åŒ– PaddleOCR å¼•æ“ (åŸºäºæµ‹è¯•ç»“æœä¼˜åŒ–)...")
    
    init_start_time = time.time()
    try:
        # print(f"[PID: {pid}] PaddleOCRåˆå§‹åŒ–å‚æ•°: {ocr_kwargs}")
        
        # ä½¿ç”¨PaddleOCR 3.x APIåˆå§‹åŒ– - æ‰€æœ‰å‚æ•°å·²ä¼˜åŒ–
        from paddleocr import PaddleOCR
        ocr_engine_process_global = PaddleOCR(**ocr_kwargs)
        
        init_end_time = time.time()
        init_duration = init_end_time - init_start_time
        print(f"[PID: {pid}] âœ… PaddleOCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ (è¯­è¨€: {ocr_kwargs['lang']}, æ¨¡å‹: {ocr_kwargs['ocr_version']}, è€—æ—¶: {init_duration:.2f}s)")
        
    except Exception as e:
        print(f"[PID: {pid}] âŒ PaddleOCRå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        ocr_engine_process_global = None


def _ocr_worker_task(task_data):
    """
    å¤šè¿›ç¨‹OCRå·¥ä½œä»»åŠ¡å‡½æ•°ã€‚
    å¤„ç†å•ä¸ªframeçš„OCRè¯†åˆ«ã€‚
    å‚è€ƒsimple_test.pyä¸­çš„ocr_worker_taskå®ç°ã€‚
    
    Args:
        task_data: (frame_idx, image_data) å…ƒç»„
        
    Returns:
        (frame_idx, texts, boxes) æˆ– None (å¦‚æœå¤„ç†å¤±è´¥)
    """
    global ocr_engine_process_global, debug_frame_counter
    pid = os.getpid()
    frame_idx, image_data = task_data
    
    if not ocr_engine_process_global:
        print(f"[PID: {pid}] é”™è¯¯: OCRå¼•æ“æœªæ­£ç¡®åˆå§‹åŒ–")
        return None
    
    try:
        # ğŸ” å…³é”®è°ƒè¯•ï¼šæ£€æŸ¥ä¼ é€’ç»™PaddleOCRçš„å›¾åƒæ•°æ®
        # print(f"[PID: {pid}] ğŸ” OCRè¾“å…¥è°ƒè¯•: image_data.shape={image_data.shape}, dtype={image_data.dtype}")
        # print(f"[PID: {pid}] ğŸ” é¢„æœŸå°ºå¯¸åº”ä¸ºå­—å¹•æ¡: é«˜åº¦~80, å®½åº¦~1280")
        
        # ğŸ¯ å…³é”®ä¿®å¤ï¼šç¡®ä¿å›¾åƒæ•°æ®æ ¼å¼ç¬¦åˆPaddleOCR 3.xè¦æ±‚
        if image_data.dtype != np.uint8:
            print(f"[PID: {pid}] ğŸ”§ ä¿®å¤dtype: {image_data.dtype} -> uint8")
            image_data = image_data.astype(np.uint8)
        
        # ç¡®ä¿å›¾åƒæ•°æ®æ˜¯è¿ç»­çš„å†…å­˜å¸ƒå±€
        if not image_data.flags['C_CONTIGUOUS']:
            print(f"[PID: {pid}] ğŸ”§ ä¿®å¤å†…å­˜å¸ƒå±€: è½¬ä¸ºè¿ç»­å†…å­˜")
            image_data = np.ascontiguousarray(image_data)
        
        # æ£€æŸ¥å¹¶ä¿®å¤å›¾åƒå°ºå¯¸èŒƒå›´
        height, width, channels = image_data.shape
        if height > 4000 or width > 4000:
            print(f"[PID: {pid}] âš ï¸  å›¾åƒå°ºå¯¸å¼‚å¸¸: {height}x{width}, éœ€è¦è°ƒæ•´")
            # è¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œä½†ä½œä¸ºå®‰å…¨æ£€æŸ¥
            max_dim = 4000
            if height > max_dim or width > max_dim:
                scale = min(max_dim/height, max_dim/width)
                new_height = int(height * scale)
                new_width = int(width * scale)
                print(f"[PID: {pid}] ğŸ”§ ç¼©æ”¾å›¾åƒ: {height}x{width} -> {new_height}x{new_width}")
                import cv2
                image_data = cv2.resize(image_data, (new_width, new_height))
        
        # print(f"[PID: {pid}] ğŸ¯ æœ€ç»ˆè¾“å…¥PaddleOCR: shape={image_data.shape}, dtype={image_data.dtype}")
        
        ocr_start_time = time.time()
        # ä½¿ç”¨predictæ–¹æ³•æ›¿ä»£ocræ–¹æ³•ï¼Œä¸simple_test.pyä¿æŒä¸€è‡´
        ocr_output = ocr_engine_process_global.predict(image_data)
        ocr_end_time = time.time()
        ocr_duration = ocr_end_time - ocr_start_time
        
        # OCRè¯†åˆ«å®Œæˆï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
        
        # è§£æOCRç»“æœ - åŸºäºsimple_test.pyçš„format_ocr_resultså‡½æ•°å¤„ç†predictæ–¹æ³•è¿”å›çš„å­—å…¸æ ¼å¼
        if ocr_output and isinstance(ocr_output, list) and len(ocr_output) > 0:
            try:
                # predictæ–¹æ³•è¿”å›å­—å…¸æ ¼å¼æ•°æ®ï¼Œå‚è€ƒsimple_test.pyçš„format_ocr_resultså®ç°
                if isinstance(ocr_output[0], dict):
                    # å¤„ç†å­—å…¸æ ¼å¼æ•°æ®ï¼ˆpredictæ–¹æ³•ï¼‰
                    data_dict = ocr_output[0]
                    
                    positions = data_dict.get('rec_polys', [])
                    texts = data_dict.get('rec_texts', [])
                    confidences = data_dict.get('rec_scores', [])
                    
                    # æ£€æµ‹åˆ°æ–‡æœ¬åŒºåŸŸï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                    
                    extracted_texts = []
                    extracted_boxes = []
                    
                    # ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆé˜¶æ®µ2ï¼šOCRè¯†åˆ«åå¸¦æ ‡æ³¨çš„å›¾åƒï¼‰
                    debug_frame_counter += 1
                    # å·²æ³¨é‡Šè°ƒè¯•å›¾åƒä¿å­˜åŠŸèƒ½ï¼Œé¿å…ç£ç›˜ç©ºé—´å ç”¨
                    # if debug_frame_counter <= 10:
                    #     _save_debug_image_with_annotations(image_data, frame_idx, positions, texts, confidences)
                    
                    for i in range(len(texts)):
                        if texts[i] and texts[i].strip():
                            extracted_texts.append(texts[i].strip())
                            
                            # å¤„ç†è¾¹ç•Œæ¡†
                            if i < len(positions):
                                try:
                                    position = positions[i]
                                    if hasattr(position, 'tolist'):
                                        box_data = position.tolist()
                                    else:
                                        box_data = position
                                    
                                    if isinstance(box_data, (list, np.ndarray)):
                                        box_array = np.array(box_data, dtype=np.float32)
                                        if box_array.size > 0 and not np.isnan(box_array).any():
                                            extracted_boxes.append(box_array.tolist())
                                            # æå–æ–‡æœ¬æˆåŠŸï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                                except Exception as box_err:
                                    # è¾¹ç•Œæ¡†å¤„ç†å¤±è´¥ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                                    pass
                    
                    return (frame_idx, extracted_texts, extracted_boxes)
                    
                else:
                    # å¤„ç†åˆ—è¡¨æ ¼å¼æ•°æ®ï¼ˆocræ–¹æ³•çš„å…¼å®¹æ€§å¤„ç†ï¼‰
                    texts = []
                    boxes = []
                    
                    # è§£æOCRç»“æœï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                    
                    # ä¿å­˜è°ƒè¯•å›¾åƒï¼ˆé˜¶æ®µ2ï¼šOCRè¯†åˆ«åå¸¦æ ‡æ³¨çš„å›¾åƒï¼‰
                    debug_frame_counter += 1
                    # å·²æ³¨é‡Šè°ƒè¯•å›¾åƒä¿å­˜åŠŸèƒ½ï¼Œé¿å…ç£ç›˜ç©ºé—´å ç”¨
                    # if debug_frame_counter <= 10:
                    #     _save_debug_image_with_annotations_list(image_data, frame_idx, ocr_output[0])
                    
                    for i, line in enumerate(ocr_output[0]):
                        if len(line) >= 2 and line[1]:
                            # æå–æ–‡æœ¬ (line[1][0])
                            text_info = line[1]
                            if isinstance(text_info, (list, tuple)) and len(text_info) > 0:
                                text = str(text_info[0]) if text_info[0] else ""
                                if text.strip():
                                    texts.append(text.strip())
                                    # æå–æ–‡æœ¬æˆåŠŸï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                                    
                                    # æå–è¾¹ç•Œæ¡† (line[0])
                                    if line[0] is not None:
                                        try:
                                            box_data = line[0]
                                            if isinstance(box_data, (list, np.ndarray)):
                                                box_array = np.array(box_data, dtype=np.float32)
                                                if box_array.size > 0 and not np.isnan(box_array).any():
                                                    boxes.append(box_array.tolist())
                                        except (ValueError, TypeError) as box_err:
                                            # è¾¹ç•Œæ¡†è½¬æ¢å¤±è´¥ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                                            pass
                            elif isinstance(text_info, str):
                                # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœtext_infoç›´æ¥æ˜¯å­—ç¬¦ä¸²
                                if text_info.strip():
                                    texts.append(text_info.strip())
                                    # æå–æ–‡æœ¬æˆåŠŸï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                                    
                                    # å°è¯•æå–è¾¹ç•Œæ¡†
                                    if line[0] is not None:
                                        try:
                                            box_data = line[0]
                                            if isinstance(box_data, (list, np.ndarray)):
                                                box_array = np.array(box_data, dtype=np.float32)
                                                if box_array.size > 0 and not np.isnan(box_array).any():
                                                    boxes.append(box_array.tolist())
                                        except (ValueError, TypeError) as box_err:
                                            # è¾¹ç•Œæ¡†è½¬æ¢å¤±è´¥ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                                            pass
                            else:
                                # æ–‡æœ¬ä¿¡æ¯æ ¼å¼å¼‚å¸¸ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                                pass
                    
                    return (frame_idx, texts, boxes)
                
            except Exception as parse_error:
                # OCRç»“æœè§£æå¤±è´¥ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
                import traceback
                traceback.print_exc()
                return (frame_idx, [], [])
        else:
            # æœªæ£€æµ‹åˆ°æ–‡æœ¬ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
            return (frame_idx, [], [])
            
    except Exception as e:
        # OCRå¤„ç†å¤±è´¥ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
        return None


def _save_debug_image_with_annotations(image_data, frame_idx, positions, texts, confidences):
    """ä¿å­˜å¸¦æ ‡æ³¨çš„è°ƒè¯•å›¾åƒï¼ˆå­—å…¸æ ¼å¼ï¼‰ - å·²æ³¨é‡Šï¼Œé¿å…ç£ç›˜ç©ºé—´å ç”¨"""
    pass
    # åŸå‡½æ•°ä½“å·²æ³¨é‡Šï¼Œé¿å…ç£ç›˜ç©ºé—´å ç”¨
    # try:
    #     debug_dir = "./pics"
    #     os.makedirs(debug_dir, exist_ok=True)
    #     debug_image = image_data.copy()
    #     if len(debug_image.shape) == 3 and debug_image.shape[2] == 3:
    #         debug_image = cv2.cvtColor(debug_image, cv2.COLOR_RGB2BGR)
    #     for i, (pos, text, conf) in enumerate(zip(positions, texts, confidences)):
    #         if pos is not None and text:
    #             try:
    #                 if isinstance(pos, (list, np.ndarray)):
    #                     box = np.array(pos, dtype=np.int32)
    #                     if box.shape[0] >= 4:
    #                         cv2.polylines(debug_image, [box], True, (0, 0, 255), 2)
    #                         x = int(box[0][0])
    #                         y = int(box[3][1]) + 20
    #                         text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
    #                         cv2.rectangle(debug_image, (x, y - text_size[1] - 5), (x + text_size[0], y + 5), (0, 0, 255), -1)
    #                         cv2.putText(debug_image, text, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    #             except Exception as box_err:
    #                 print(f"ç»˜åˆ¶è¾¹ç•Œæ¡†å¤±è´¥: {box_err}")
    #     debug_path = os.path.join(debug_dir, f"stage2_annotated_frame_{frame_idx:06d}.jpg")
    #     cv2.imwrite(debug_path, debug_image)
    # except Exception as e:
    #     print(f"ä¿å­˜è°ƒè¯•å›¾åƒå¤±è´¥: {e}")


def _save_debug_image_with_annotations_list(image_data, frame_idx, ocr_results):
    """ä¿å­˜å¸¦æ ‡æ³¨çš„è°ƒè¯•å›¾åƒï¼ˆåˆ—è¡¨æ ¼å¼ï¼‰ - å·²æ³¨é‡Šï¼Œé¿å…ç£ç›˜ç©ºé—´å ç”¨"""
    pass
    # åŸå‡½æ•°ä½“å·²æ³¨é‡Šï¼Œé¿å…ç£ç›˜ç©ºé—´å ç”¨
    # try:
    #     debug_dir = "./pics"
    #     os.makedirs(debug_dir, exist_ok=True)
    #     
    #     # å¤åˆ¶å›¾åƒæ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    #     debug_image = image_data.copy()
    #     
    #     # è½¬æ¢ä¸ºBGRæ ¼å¼ç”¨äºOpenCV
    #     if len(debug_image.shape) == 3 and debug_image.shape[2] == 3:
    #         debug_image = cv2.cvtColor(debug_image, cv2.COLOR_RGB2BGR)
    #     
    #     # ç»˜åˆ¶æ ‡æ³¨
    #     for line in ocr_results:
    #         if len(line) >= 2 and line[1]:
    #             try:
    #                 box = line[0]  # è¾¹ç•Œæ¡†
    #                 text_info = line[1]  # æ–‡æœ¬ä¿¡æ¯
    #                 
    #                 # è·å–æ–‡æœ¬
    #                 if isinstance(text_info, (list, tuple)) and len(text_info) > 0:
    #                     text = str(text_info[0]) if text_info[0] else ""
    #                 elif isinstance(text_info, str):
    #                     text = text_info
    #                 else:
    #                     continue
    #                 
    #                 if not text.strip():
    #                     continue
    #                 
    #                 # ç»˜åˆ¶è¾¹ç•Œæ¡†
    #                 if box is not None and isinstance(box, (list, np.ndarray)):
    #                     box_array = np.array(box, dtype=np.int32)
    #                     if box_array.size > 0:
    #                         # ç»˜åˆ¶çº¢è‰²è¾¹ç•Œæ¡†
    #                         cv2.polylines(debug_image, [box_array], True, (0, 0, 255), 2)
    #                         
    #                         # åœ¨è¾¹ç•Œæ¡†ä¸‹æ–¹ç»˜åˆ¶æ–‡æœ¬
    #                         x = int(box_array[0][0])  # å·¦ä¸Šè§’xåæ ‡
    #                         y = int(box_array[3][1]) + 20  # å·¦ä¸‹è§’yåæ ‡ + åç§»
    #                         
    #                         # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯
    #                         text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
    #                         cv2.rectangle(debug_image, (x, y - text_size[1] - 5), 
    #                                     (x + text_size[0], y + 5), (0, 0, 255), -1)
    #                         
    #                         # ç»˜åˆ¶ç™½è‰²æ–‡æœ¬
    #                         cv2.putText(debug_image, text, (x, y), 
    #                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
    #                         
    #             except Exception as box_err:
    #                 print(f"ç»˜åˆ¶è¾¹ç•Œæ¡†å¤±è´¥: {box_err}")
    #     
    #     # ä¿å­˜å›¾åƒ
    #     debug_path = os.path.join(debug_dir, f"stage2_annotated_frame_{frame_idx:06d}.jpg")
    #     cv2.imwrite(debug_path, debug_image)
    #     
    # except Exception as e:
    #     print(f"ä¿å­˜è°ƒè¯•å›¾åƒå¤±è´¥: {e}")
