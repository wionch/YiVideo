#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Pyannote Audio Service ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ pyannote_audio.diarize_speakers å·¥ä½œæµèŠ‚ç‚¹
"""

import os
import json
from pathlib import Path
import tempfile

def create_sample_audio():
    """åˆ›å»ºç¤ºä¾‹éŸ³é¢‘æ–‡ä»¶"""
    try:
        import numpy as np
        import soundfile as sf

        # åˆ›å»ºç®€å•çš„æµ‹è¯•éŸ³é¢‘
        sample_rate = 16000
        duration = 10.0
        t = np.linspace(0., duration, int(sample_rate * duration))

        # ç”Ÿæˆæµ‹è¯•ä¿¡å· (ä¸¤ä¸ªä¸åŒé¢‘ç‡çš„æ­£å¼¦æ³¢æ¨¡æ‹Ÿä¸åŒè¯´è¯äºº)
        # å‰5ç§’æ˜¯è¯´è¯äºº1 (440 Hz)
        audio_data1 = np.sin(2. * np.pi * 440 * t[:len(t)//2])

        # å5ç§’æ˜¯è¯´è¯äºº2 (880 Hz)
        audio_data2 = np.sin(2. * np.pi * 880 * t[len(t)//2:])

        # åˆå¹¶
        audio_data = np.concatenate([audio_data1, audio_data2])

        # ä¿å­˜ä¸ºWAVæ–‡ä»¶
        audio_path = "/tmp/sample_audio.wav"
        sf.write(audio_path, audio_data, sample_rate)

        return audio_path

    except ImportError:
        print("âš ï¸  éŸ³é¢‘ç”Ÿæˆåº“æœªå®‰è£…ï¼Œè·³è¿‡ç¤ºä¾‹éŸ³é¢‘åˆ›å»º")
        return None

def demo_workflow_context():
    """æ¼”ç¤ºå·¥ä½œæµä¸Šä¸‹æ–‡é…ç½®"""
    print("ğŸ¯ å·¥ä½œæµä¸Šä¸‹æ–‡ç¤ºä¾‹:")

    # ç¤ºä¾‹å·¥ä½œæµä¸Šä¸‹æ–‡
    context = {
        "workflow_id": "demo_workflow_001",
        "input_params": {
            "video_path": "/share/videos/sample.mp4",
            "output_dir": "/share/workflows/demo_001"
        },
        "stages": [
            {
                "name": "extract_audio",
                "service": "ffmpeg_service",
                "task": "extract_audio",
                "status": "completed",
                "result": {
                    "audio_path": "/share/workflows/demo_001/audio.wav"
                }
            }
        ],
        "error": None
    }

    # æ·»åŠ pyannote_audioä»»åŠ¡
    context["stages"].append({
        "name": "diarize_speakers",
        "service": "pyannote_audio_service",
        "task": "pyannote_audio.diarize_speakers",
        "status": "pending",
        "context": context
    })

    print(json.dumps(context, indent=2, ensure_ascii=False))
    return context

def demo_diarize_speakers_usage():
    """æ¼”ç¤ºè¯´è¯äººåˆ†ç¦»ä»»åŠ¡ä½¿ç”¨æ–¹æ³•"""
    print("\nğŸ¤ è¯´è¯äººåˆ†ç¦»ä»»åŠ¡ä½¿ç”¨ç¤ºä¾‹:")

    # åˆ›å»ºç¤ºä¾‹éŸ³é¢‘
    audio_path = create_sample_audio()

    if audio_path and os.path.exists(audio_path):
        print(f"âœ… å·²åˆ›å»ºç¤ºä¾‹éŸ³é¢‘: {audio_path}")

        # æ„å»ºä»»åŠ¡ä¸Šä¸‹æ–‡
        context = {
            "workflow_id": "demo_diarization_001",
            "input_params": {
                "audio_path": audio_path
            },
            "stages": [],
            "error": None
        }

        print("ğŸ“‹ ä»»åŠ¡ä¸Šä¸‹æ–‡:")
        print(json.dumps(context, indent=2, ensure_ascii=False))

        # æ³¨æ„ï¼šè¿™é‡Œåªæ˜¯æ¼”ç¤ºï¼Œå®é™…çš„diarize_speakersä»»åŠ¡éœ€è¦é€šè¿‡Celeryè°ƒç”¨
        # åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œä¼šè¿™æ ·è°ƒç”¨ï¼š
        # from tasks import diarize_speakers
        # result = diarize_speakers(context)
        # print("ä»»åŠ¡ç»“æœ:", result)

    else:
        print("âš ï¸  æ— æ³•åˆ›å»ºç¤ºä¾‹éŸ³é¢‘ï¼Œè¯·ç¡®ä¿æœ‰éŸ³é¢‘æ–‡ä»¶ç”¨äºæµ‹è¯•")

def demo_result_format():
    """æ¼”ç¤ºç»“æœæ ¼å¼"""
    print("\nğŸ“Š è¯´è¯äººåˆ†ç¦»ç»“æœæ ¼å¼ç¤ºä¾‹:")

    # ç¤ºä¾‹ç»“æœ
    sample_result = {
        "success": True,
        "data": {
            "diarization_file": "/share/workflows/demo_001/diarization_result.json",
            "speaker_segments": [
                {
                    "start": 0.0,
                    "end": 2.5,
                    "speaker": "SPEAKER_00",
                    "duration": 2.5
                },
                {
                    "start": 3.0,
                    "end": 5.5,
                    "speaker": "SPEAKER_01",
                    "duration": 2.5
                },
                {
                    "start": 6.0,
                    "end": 8.5,
                    "speaker": "SPEAKER_00",
                    "duration": 2.5
                },
                {
                    "start": 9.0,
                    "end": 10.0,
                    "speaker": "SPEAKER_01",
                    "duration": 1.0
                }
            ],
            "total_speakers": 2,
            "summary": "æ£€æµ‹åˆ° 2 ä¸ªè¯´è¯äººï¼Œå…± 4 ä¸ªè¯´è¯ç‰‡æ®µ"
        }
    }

    print("ğŸ“‹ ä»»åŠ¡ç»“æœç¤ºä¾‹:")
    print(json.dumps(sample_result, indent=2, ensure_ascii=False))

    # ç¤ºä¾‹è¯¦ç»†çš„diarizationç»“æœæ–‡ä»¶
    diarization_result = {
        "workflow_id": "demo_001",
        "audio_path": "/share/workflows/demo_001/audio.wav",
        "total_speakers": 2,
        "segments": [
            {
                "start": 0.0,
                "end": 2.5,
                "speaker": "SPEAKER_00",
                "duration": 2.5
            },
            {
                "start": 3.0,
                "end": 5.5,
                "speaker": "SPEAKER_01",
                "duration": 2.5
            },
            {
                "start": 6.0,
                "end": 8.5,
                "speaker": "SPEAKER_00",
                "duration": 2.5
            },
            {
                "start": 9.0,
                "end": 10.0,
                "speaker": "SPEAKER_01",
                "duration": 1.0
            }
        ],
        "metadata": {
            "model": "pyannote/speaker-diarization-community-1",
            "mode": "local",
            "processing_time": 15.3
        }
    }

    print("\nğŸ“‹ è¯¦ç»†çš„diarizationç»“æœæ–‡ä»¶ç¤ºä¾‹:")
    print(json.dumps(diarization_result, indent=2, ensure_ascii=False))

def demo_config_examples():
    """æ¼”ç¤ºé…ç½®ç¤ºä¾‹"""
    print("\nâš™ï¸  é…ç½®ç¤ºä¾‹:")

    print("ğŸ“„ config.yml ä¸­çš„é…ç½®:")
    config_example = """
# 14. Pyannote Audio Service é…ç½® (æ–°å¢)
# åŸºäº pyannote.audio çš„è¯´è¯äººåˆ†ç¦»æœåŠ¡
pyannote_audio_service:
  # === æ¨¡å¼é…ç½® ===
  # ä½¿ç”¨æ¨¡å¼: "local" (æœ¬åœ°æ¨¡å¼) æˆ– "api" (pyannoteAI APIæ¨¡å¼)
  use_paid_api: false

  # === æœ¬åœ°æ¨¡å¼é…ç½® ===
  # Hugging Face Token (ç”¨äºè®¿é—®HuggingFaceæ¨¡å‹)
  hf_token: "your_hf_token_here"

  # === APIæ¨¡å¼é…ç½® ===
  # PyannoteAI API Key (APIæ¨¡å¼éœ€è¦)
  pyannoteai_api_key: ""

  # === æ¨¡å‹é…ç½® ===
  # è¯´è¯äººåˆ†ç¦»æ¨¡å‹é€‰æ‹©
  diarization_model: "pyannote/speaker-diarization-community-1"

  # === å¤„ç†é…ç½® ===
  # éŸ³é¢‘é‡‡æ ·ç‡
  audio_sample_rate: 16000
  # æœ€å°ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
  min_segment_duration: 0.5
  # æœ€å¤§ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
  max_segment_duration: 30.0

  # === GPUé…ç½® ===
  # æ˜¯å¦å¯ç”¨GPUé”æœºåˆ¶
  enable_gpu_lock: true
  # GPUè®¾å¤‡IDï¼Œ0è¡¨ç¤ºç¬¬ä¸€ä¸ªGPU
  gpu_device_id: 0

  # === è´¨é‡æ§åˆ¶ ===
  # æœ€å°è¯´è¯äººæ•°é‡
  min_speakers: 1
  # æœ€å¤§è¯´è¯äººæ•°é‡
  max_speakers: 10

  # === ç›‘æ§é…ç½® ===
  # æ—¥å¿—çº§åˆ«
  log_level: "INFO"
"""

    print(config_example)

    print("ğŸŒ ç¯å¢ƒå˜é‡é…ç½®:")
    env_example = """
# ç¯å¢ƒå˜é‡é…ç½® (é€šè¿‡ .env æ–‡ä»¶è®¾ç½®)

# Hugging Face Token (æœ¬åœ°æ¨¡å¼éœ€è¦)
HF_TOKEN=your_huggingface_token_here

# PyannoteAI API Key (APIæ¨¡å¼éœ€è¦)
PYANNOTEAI_API_KEY=your_pyannoteai_api_key_here

# Redisè¿æ¥
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/1
"""

    print(env_example)

def demo_workflow_integration():
    """æ¼”ç¤ºå·¥ä½œæµé›†æˆç¤ºä¾‹"""
    print("\nğŸ”„ å®Œæ•´å·¥ä½œæµé›†æˆç¤ºä¾‹:")

    print("å·¥ä½œæµé…ç½®æ–‡ä»¶ç¤ºä¾‹:")
    workflow_example = {
        "workflow_chain": [
            "ffmpeg.extract_audio",
            "faster_whisper.transcribe_audio",
            "pyannote_audio.diarize_speakers",
            "faster_whisper.generate_subtitle_files"
        ],
        "input_params": {
            "video_path": "/share/videos/input/example.mp4",
            "workflow_config": {
                "subtitle_generation": {
                    "strategy": "asr",
                    "provider": "whisperx"
                },
                "speaker_diarization": {
                    "strategy": "pyannote",
                    "provider": "pyannote_audio"
                }
            }
        }
    }

    print(json.dumps(workflow_example, indent=2, ensure_ascii=False))

    print("\nğŸ“‹ å‰ç«¯APIè°ƒç”¨ç¤ºä¾‹:")
    api_example = """
# åˆ›å»ºå’Œæ‰§è¡Œå·¥ä½œæµ
curl -X POST http://localhost:8788/v1/workflows \\
  -H "Content-Type: application/json" \\
  -d '{
    "video_path": "/share/videos/input/example.mp4",
    "workflow_chain": [
      "ffmpeg.extract_audio",
      "faster_whisper.transcribe_audio",
      "pyannote_audio.diarize_speakers",
      "faster_whisper.generate_subtitle_files"
    ]
  }'
"""

    print(api_example)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Pyannote Audio Service ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)

    demo_workflow_context()
    demo_diarize_speakers_usage()
    demo_result_format()
    demo_config_examples()
    demo_workflow_integration()

    print("\n" + "=" * 50)
    print("ğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("1. ç¡®ä¿é…ç½®å¥½ Hugging Face Token æˆ– PyannoteAI API Key")
    print("2. å‡†å¤‡éŸ³é¢‘æ–‡ä»¶ (æ¨è WAV æ ¼å¼)")
    print("3. é€šè¿‡å·¥ä½œæµè°ƒç”¨ pyannote_audio.diarize_speakers ä»»åŠ¡")
    print("4. æŸ¥çœ‹ç»“æœä¸­çš„è¯´è¯äººç‰‡æ®µä¿¡æ¯")
    print("5. æ ¹æ®éœ€è¦ä½¿ç”¨ get_speaker_segments å’Œ validate_diarization ä»»åŠ¡")

if __name__ == "__main__":
    main()